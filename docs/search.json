[{"path":"/articles/example.html","id":"purpose-of-this-example","dir":"Articles","previous_headings":"","what":"Purpose of This Example","title":"Quick Simulated Example with LBCNet","text":"example demonstrates apply LBCNet simulated dataset inspired misspecified propensity score model Kang & Schafer (2007). goal estimate mean outcome, assess covariate balance, evaluate propensity score calibration using local system Python.","code":""},{"path":"/articles/example.html","id":"simulate-the-data","dir":"Articles","previous_headings":"","what":"Simulate the Data","title":"Quick Simulated Example with LBCNet","text":"simulate data true propensity score model differs one used analysis, representing challenging scenario causal inference (misspecified propensity score model).","code":"# Load required packages library(MASS)  # Set seed for reproducibility set.seed(123456)  # Define sample size n <- 5000  # Generate true covariates from a multivariate normal distribution Z <- MASS::mvrnorm(n, mu = rep(0, 4), Sigma = diag(4))  # Generate true propensity scores prop <- 1 / (1 + exp(Z[,1] - 0.5 * Z[,2] + 0.25 * Z[,3] + 0.1 * Z[,4]))  # Assign treatment based on propensity scores Tr <- rbinom(n, 1, prop)  # Generate continuous outcome (correct model) Y <- 210 + 27.4 * Z[,1] + 13.7 * Z[,2] + 13.7 * Z[,3] + 13.7 * Z[,4] + rnorm(n)  # Create a set of covariates for estimation (misspecified model) X <- cbind(   exp(Z[,1] / 2),   Z[,2] * (1 + exp(Z[,1]))^(-1) + 10,   ((Z[,1] * Z[,3]) / 25 + 0.6)^3,   (Z[,2] + Z[,4] + 20)^2 )  # Combine data into a data frame data <- data.frame(Y, Tr, X) colnames(data) <- c(\"Y\", \"Tr\", \"X1\", \"X2\", \"X3\", \"X4\")  # Quick look at the data head(data) Y Tr        X1        X2        X3       X4 1 267.0934  1 2.0995290 10.136751 0.1936739 465.4067 2 211.1973  1 1.0944490 10.811059 0.2031783 462.5301 3 190.5548  1 1.1113093  9.313208 0.2168326 327.9726 4 209.1748  1 0.9292040 10.001453 0.2145796 403.6159 5 198.9068  1 0.4234368 10.261615 0.2123729 508.9887 6 235.8486  0 0.7080015 11.445936 0.2109414 529.2390"},{"path":"/articles/example.html","id":"set-up-python-environment-using-a-virtual-environment","dir":"Articles","previous_headings":"","what":"Set Up Python Environment Using a Virtual Environment","title":"Quick Simulated Example with LBCNet","text":"example, set LBCNet run Python virtual environment called \"r-lbcnet\". Using virtual environment ensures Python packages needed LBCNet installed isolated projects. , envname = \"r-lbcnet\" specifies name Python virtual environment create_if_missing = FALSE means LBCNet automatically create new virtual environment install necessary Python dependencies (like torch) doesn’t already exist.","code":"library(LBCNet)  # Set up LBCNet to use a virtual environment named \"r-lbcnet\" setup_lbcnet(   envname = \"r-lbcnet\",       # Name of the virtual environment   create_if_missing = TRUE   # Set to TRUE if you want LBCNet to create the environment automatically if it doesn't exist )"},{"path":"/articles/example.html","id":"fit-the-lbc-net-model","dir":"Articles","previous_headings":"","what":"Fit the LBC-Net Model","title":"Quick Simulated Example with LBCNet","text":"Estimate propensity scores using LBC-Net covariates X1, X2, X3, X4, compute causal estimator (Inverse Probability Weighting estimator) ATE.","code":"# Fit the LBC-Net model lbc_net.fit <- lbc_net(   data = data,   formula = Tr ~ X1 + X2 + X3 + X4,   Y = data$Y,   estimand = \"ATE\" ) Python is already set up. Skipping `setup_lbcnet()`. Calculating propensity scores for ck/h calculation... ⚠️ Stopping criterion not met at max epochs. Try increasing `max_epochs` or adjusting `lsd_threshold` for better convergence. Starting post-processing: computing treatment effect and variance... ✅ LBC-Net training completed successfully. # Print the model fit object print(lbc_net.fit) Call: Tr ~ X1 + X2 + X3 + X4 Sample Size: 5000  | Treated: 2466  | Control: 2534 Estimand: ATE (Average Treatment Effect)  --- Training Results --- Final Loss Value: 840.804 Max LSD: 3.92% Mean LSD: 0.40%  --- Model Hyperparameters --- Hidden Layers: 1 | Hidden Units: 100 VAE Learning Rate: 0.010 | LBC-Net Learning Rate: 0.050 Weight Decay: 1.0e-05 | Balance Lambda: 1.00 Kernel: \"gaussian\"  --- Stopping Criteria --- LSD Threshold: 2.00% | Rolling Window: 5 Max Training Epochs: 5000  --- Treatment Effect (stored in object) --- Estimand: ATE (Average Treatment Effect) Effect:   -3.3174 SE:       0.4207 95% CI:   [-4.1419, -2.4928]  Use summary(object) for a full model summary."},{"path":"/articles/example.html","id":"evaluate-propensity-score-estimation-performance","dir":"Articles","previous_headings":"","what":"Evaluate Propensity Score Estimation Performance","title":"Quick Simulated Example with LBCNet","text":"Summarize model visualize estimated propensity scores.","code":"# Summarize the fitted model summary(lbc_net.fit) Call:  Tr ~ X1 + X2 + X3 + X4 Sample Size: 5000  | Number of Covariates: 4 Treated: 2466  | Control: 2534  --- Losses --- Total Loss: 840.8040  --- Local Balance (LSD) % --- Max LSD:   3.9247 Mean LSD:  0.4018  --- Global Standardized Differences (GSD) % --- Covariate      Pre-GSD     Post-GSD -------------------------------- X1       -78.1284      -0.2568 X2        40.5772       0.2748 X3        -5.9774      -0.0084 X4        21.7461       0.0223  --- Treatment Effect Estimate --- ATE: -3.3174  (SE: 0.4207)  95% CI: [-4.1419, -2.4928] # Mirror histogram for covariate distribution balance mirror_hist(lbc_net.fit) # Calibration plot to assess model calibration plot_calib(lbc_net.fit)"},{"path":"/articles/example.html","id":"evaluate-covariate-balance","dir":"Articles","previous_headings":"","what":"Evaluate Covariate Balance","title":"Quick Simulated Example with LBCNet","text":"detailed tutorial, visit Step--Step Tutorial.","code":"# Compute local balance diagnostics lsd.fit <- lsd(lbc_net.fit)  # Print and summarize local balance print(lsd.fit) Sample Size: 5000  | Treated: 2466  | Control: 2534 Estimand: ATE (Average Treatment Effect)  --- Local Balance (LSD) % --- Max LSD: 3.9246 Mean LSD: 0.4018  Kernel: \"gaussian\"  Use summary(object) for a full model summary. summary(lsd.fit) Call:  function (x, ...)  UseMethod(\"formula\") Sample Size: 5000  | Number of Covariates: 4 Treated: 2466  | Control: 2534 Estimand: ATE (Average Treatment Effect)  --- Local Balance (LSD) % --- Max LSD:   3.9246 Mean LSD:  0.4018  Covariates   LSD % ------------- X1    0.8687 X2    0.3959 X3    0.1678 X4    0.1749 # Plot local balance metrics plot(lsd.fit)"},{"path":"/articles/tutorial.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Tutorial for LBCNet pacakge","text":"Welcome LBCNet tutorial! guide provides detailed introduction LBCNet package demonstrates use causal inference analyses. LBC-Net stands Local Balance Calibration implemented Neural Networks. package offers set tools estimating propensity scores nonparametric flexible manner using deep neural networks, along comprehensive diagnostics visualization utilities. LBCNet several key objectives. First, provides accurate propensity score estimation support causal effect estimation, including average treatment effect (ATE) average treatment effect treated (ATT). Second, offers diagnostic tools assess quality estimated propensity scores, evaluations covariate balance, propensity score distributions, checks local balance local calibration. Third, LBCNet includes tools variance estimation plug-influence-function methods, enabling uncertainty quantification point estimates weighted estimators. Finally, package now supports survival outcome estimands, including IPW-adjusted survival differences risk differences fixed time ( t ), extending LBC-Net’s framework time--event analyses. Propensity score methods become cornerstone addressing confounding observational studies. concept propensity score—defined probability treatment assignment conditional observed covariates—introduced Rosenbaum Rubin (1983). strong ignorability assumption, adjusting propensity score allows unbiased estimation causal effects. key feature balancing property: given propensity score, distribution covariates similar treatment groups. Achieving good covariate balance essential reducing bias. LBC-Net directly targets covariate balance two theoretical principles: local balance, enforces covariate balance across dense grid balancing scores, local calibration, ensures balancing scores correspond true propensity scores. Neural networks used optimize conditions due flexibility modeling complex, nonlinear, high-dimensional relationships. tutorial walks process setting LBCNet, including configuration Python environments via reticulate, demonstrates complete analysis using public lalonde dataset sbw package (Zubizarreta, 2024). cover choose model parameters, interpret diagnostic plots, evaluate balance, compute treatment effects. Examples variance estimation survival-based estimands also highlighted. Practical notes recommended workflows included help users apply LBC-Net effectively real-world applications. Support multiple treatment groups currently development included future release package.","code":""},{"path":"/articles/tutorial.html","id":"setup-configuring-python-for-lbcnet","dir":"Articles","previous_headings":"","what":"Setup: Configuring Python for LBCNet","title":"Tutorial for LBCNet pacakge","text":"using LBCNet, need configure Python environment. environment runs neural network model behind LBC-Net’s nonparametric propensity score estimation. package uses reticulate package manage Python environments packages within R. key function managing setup setup_lbcnet(). setup_lbcnet() configures Python environment required LBCNet. checks Python availability, ensures necessary Python packages (e.g., Torch) installed, manages virtual environments. can call setup_lbcnet() directly running lbc_net(), let lbc_net() call automatically model fitting passing arguments setup_lbcnet_args. works: Python configured, setup_lbcnet() Automatically create virtual environment named “r-lbcnet” default (create_if_missing = TRUE). install required Python packages. already virtual environment want use system Python, can customize LBCNet connects Python. default safest setup, creating dedicated Python environment LBCNet. set reticulate , simply run: create virtual environment named “r-lbcnet” doesn’t exist install necessary Python packages (TensorFlow, etc.). activates uses virtual environment. want manually create control virtual environment, can : done, lbc_net() automatically detect use environment “r-lbcnet”. multiple virtual environments, specify environment explicitly via setup_lbcnet(envname = \"r-lbcnet\"). addition, can also pass environment name calling lbc_net() using setup_lbcnet_args argument: prefer use existing system Python installation instead virtualenv Conda, can specify use_system_python = TRUE point Python executable. can use following code find available Python executables system: Note: Sys.() returns first Python executable found system. match Python path want use, specify correct path manually. specific Python executable path want use, : Alternatively, can specify calling lbc_net(): prefer Conda environments, can specify use_conda = TRUE setup_lbcnet() lbc_net() manage environments Conda instead virtualenv. details Conda environments R, refer official Reticulate Documentation. encounter issues, try reticulate::py_discover_config() see Python environment active.","code":"library(LBCNet)  # Automatically creates and sets up \"r-lbcnet\" virtual environment setup_lbcnet(create_if_missing = TRUE) library(reticulate)  # Create the virtual environment (only run once) virtualenv_create(\"r-lbcnet\")  # Activate the virtual environment in your R session use_virtualenv(\"r-lbcnet\", required = TRUE) lbc_net(   data = mydata,   formula = Tr ~ X1 + X2 + X3,   setup_lbcnet_args = list(envname = \"r-lbcnet\") ) library(LBCNet)  # Discover available Python environments available_pythons <- unique(c(   Sys.which(\"python\"),   Sys.which(\"python3\"),   reticulate::py_discover_config()$python ))  # Clean up and display results available_pythons <- available_pythons[nzchar(available_pythons)] print(available_pythons) path <- \"C:/Users/mpeng1/AppData/Local/Programs/Python/Python311/python.exe\" ## change it to your path  # Set up LBCNet to use system Python setup_lbcnet(use_system_python = TRUE, system_python_path = path) lbc_net(   data = mydata,   formula = Tr ~ X1 + X2 + X3,   Y = Y,   setup_lbcnet_args = list(     use_system_python = TRUE,     system_python_path = \"C:/Users/mpeng1/AppData/Local/Programs/Python/Python311/python.exe\"   ) )"},{"path":"/articles/tutorial.html","id":"option-1-virtual-environment-recommended","dir":"Articles","previous_headings":"","what":"Option 1: Virtual Environment (Recommended)","title":"Tutorial for LBCNet pacakge","text":"default safest setup, creating dedicated Python environment LBCNet. set reticulate , simply run: create virtual environment named “r-lbcnet” doesn’t exist install necessary Python packages (TensorFlow, etc.). activates uses virtual environment. want manually create control virtual environment, can : done, lbc_net() automatically detect use environment “r-lbcnet”. multiple virtual environments, specify environment explicitly via setup_lbcnet(envname = \"r-lbcnet\"). addition, can also pass environment name calling lbc_net() using setup_lbcnet_args argument:","code":"library(LBCNet)  # Automatically creates and sets up \"r-lbcnet\" virtual environment setup_lbcnet(create_if_missing = TRUE) library(reticulate)  # Create the virtual environment (only run once) virtualenv_create(\"r-lbcnet\")  # Activate the virtual environment in your R session use_virtualenv(\"r-lbcnet\", required = TRUE) lbc_net(   data = mydata,   formula = Tr ~ X1 + X2 + X3,   setup_lbcnet_args = list(envname = \"r-lbcnet\") )"},{"path":"/articles/tutorial.html","id":"option-2-system-python","dir":"Articles","previous_headings":"","what":"Option 2: System Python","title":"Tutorial for LBCNet pacakge","text":"prefer use existing system Python installation instead virtualenv Conda, can specify use_system_python = TRUE point Python executable. can use following code find available Python executables system: Note: Sys.() returns first Python executable found system. match Python path want use, specify correct path manually. specific Python executable path want use, : Alternatively, can specify calling lbc_net():","code":"library(LBCNet)  # Discover available Python environments available_pythons <- unique(c(   Sys.which(\"python\"),   Sys.which(\"python3\"),   reticulate::py_discover_config()$python ))  # Clean up and display results available_pythons <- available_pythons[nzchar(available_pythons)] print(available_pythons) path <- \"C:/Users/mpeng1/AppData/Local/Programs/Python/Python311/python.exe\" ## change it to your path  # Set up LBCNet to use system Python setup_lbcnet(use_system_python = TRUE, system_python_path = path) lbc_net(   data = mydata,   formula = Tr ~ X1 + X2 + X3,   Y = Y,   setup_lbcnet_args = list(     use_system_python = TRUE,     system_python_path = \"C:/Users/mpeng1/AppData/Local/Programs/Python/Python311/python.exe\"   ) )"},{"path":"/articles/tutorial.html","id":"option-3-conda-environment","dir":"Articles","previous_headings":"","what":"Option 3: Conda Environment","title":"Tutorial for LBCNet pacakge","text":"prefer Conda environments, can specify use_conda = TRUE setup_lbcnet() lbc_net() manage environments Conda instead virtualenv. details Conda environments R, refer official Reticulate Documentation. encounter issues, try reticulate::py_discover_config() see Python environment active.","code":""},{"path":"/articles/tutorial.html","id":"implementing-lbc-net-on-the-lalonde-dataset-ate-estimation","dir":"Articles","previous_headings":"","what":"Implementing LBC-Net on the lalonde Dataset (ATE Estimation)","title":"Tutorial for LBCNet pacakge","text":"dataset originates National Supported Work (NSW) Demonstration, experimental program designed evaluate impact employment training future earnings. treatment assignment indicator (treatment) specifies whether individual received job training (1 = treated, 0 = control). dataset includes pre-treatment covariates: age (years), education (years schooling), black (1 Black, 0 otherwise), hispanic (1 Hispanic, 0 otherwise), married (1 married, 0 otherwise), nodegree (1 individual high school diploma), re74 (real earnings 1974), re75 (real earnings 1975). outcome variable re78, records real earnings 1978. Lalonde dataset includes 614 observations, consisting 185 treated 429 control subjects, total 10 variables. example, use lbc_net() function estimate propensity scores binary treatment based pre-treatment covariates listed . run lbc_net() default parameters provide explanation key options users may want modify depending analysis. First, fit LBC-Net model estimate propensity score receiving abciximab treatment. use covariates predictors formula. , adjust lbc_net() parameters account small sample size limited overlap observed Lalonde dataset. mirror histogram mirror_hist() shows poor overlap treated control groups, making balance harder achieve. address , increase training iterations 15,000 epochs (max_epochs = 15000) expand local neighborhood size 40% sample (rho = 0.4). adjustments give model time optimize ensure sufficient data points within local region improve balance. choice rho important can affect model’s ability achieve good local balance global balance. Typically, rho can selected range 0.1 0.5, depending sample size degree overlap treatment groups: smaller rho (e.g., 0.1–0.2) may work well larger samples good overlap. larger rho (e.g., 0.3–0.5) recommended sample size small overlap limited, ensures enough observations local neighborhood effective balancing. practice, optimal rho can chosen evaluating model’s loss function mean global standardized difference (GSD). lower balance loss smaller mean GSD typically indicate better covariate balance improved model performance. fitting LBC-Net model using lbc_net(), next step evaluate performance quality estimated propensity scores. print() function provides quick summary training process, including training loss, local balance metrics, key indicators. detailed results, causal effect estimates covariate balance summaries, use summary() function. example, use summary() display results fitted LBC-Net model. causal effect (ATE ATT) already computed model fitting step, summary() re-estimate causal effect; instead, reports values stored fitted object along diagnostic summaries. outcome variable included directly model formula, may specify explicitly argument Y fitting model. binary continuous outcomes, ATE ATT reported summary based inverse probability treatment weights (IPTW) derived estimated propensity scores. time--event outcomes, users instead apply either () dedicated survival method provided lbc_net_surv(), weighted Cox proportional hazards model using estimated weights, e.g.: coxph(Surv(time, event) ~ abcix, data = lindner, weights = lbc_net.fit$weights). summary() output also includes covariate balance table, reports standardized mean differences weighting, global balance metric, Global Standardized Difference (GSD). GSD summarizes overall covariate imbalance across variables, expressed percentage. can extract tables summary output using summary_out$balance_table (data frame) summary_out$gsd. evaluate performance LBC-Net relative traditional methods, can compare global balance (GSD) obtained logistic regression propensity scores. another example illustrating analyze survival outcomes using lbc_net_surv() well-known Primary Biliary Cirrhosis (PBC) dataset survival package. study followed 418 patients enrolled randomized clinical trial evaluating effect drug D-penicillamine survival primary biliary cirrhosis. dataset contains patient survival time, event status, treatment assignment, number important prognostic covariates age, bilirubin level, albumin, prothrombin time. demonstration, define treatment indicator Tr = 1 active treatment arm Tr = 0 placebo, estimate survival difference median survival time (default lbc_net_surv()). example fit logistic regression model, extract predicted propensity scores, compute GSD using gsd() function.","code":"library(sbw) data(\"lalonde\")  library(LBCNet) lbc_net.fit <- lbc_net(   data = lalonde,   formula = treatment ~ age + education + black + hispanic + married + nodegree + re74 + re75,   Y = lalonde$re78,   estimand = \"ATE\",   max_epochs = 15000,   rho = 0.4 ) ⚠️ Stopping criterion not met at max epochs. Try increasing `max_epochs` or adjusting `lsd_threshold` for better convergence. Starting post-processing: computing treatment effect and variance... ✅ LBC-Net training completed successfully. summary(lbc_net.fit) Call:  treatment ~ age + education + black + hispanic + married + nodegree +      re74 + re75 Sample Size: 614  | Number of Covariates: 8 Treated: 185  | Control: 429  --- Losses --- Total Loss: 808.4491  --- Local Balance (LSD) % --- Max LSD:   6.5109 Mean LSD:  2.8801  --- Global Standardized Differences (GSD) % --- Covariate        Pre-GSD     Post-GSD --------------------------------------- age             -22.5450      -4.5855 education         4.2090       4.4651 black           163.8478       5.9168 hispanic        -25.8951      -1.5541 married         -68.8767      -1.2885 nodegree         23.2018      -2.7438 re74            -56.2210      -1.3585 re75            -28.6199      -0.4137  --- Treatment Effect Estimate --- ATE: -89.0508  (SE: 1088.5337)  95% CI: [-2222.5768, 2044.4752] library(survival) data(pbc)  pbc <- na.omit(pbc) pbc$trt <- ifelse(pbc$trt == 1, 1, 0) pbc$status <- ifelse(pbc$status == 0, 0, 1) fit_surv <- lbc_net_surv(   data = pbc,   formula = trt ~ .-time-id-status,   time = pbc$time,   delta = pbc$status ) Python is already set up. Skipping `setup_lbcnet()`. Calculating propensity scores for ck/h calculation... ⚠️ LSD stopping criterion not met by max_epochs. Consider increasing `max_epochs` or adjusting `lsd_threshold`. Starting post-processing: computing treatment effect and variance... ✅ LBC-Net survival estimation completed successfully. summary(fit_surv) Call:  trt ~ . - time - id - status Sample Size: 276 | Number of Covariates: 16 Treated: 136 | Control: 140  --- Loss --- Total Loss: 728.9798  --- Local Balance (LSD) % --- Max LSD:   13.3053 Mean LSD:  2.4379  --- Global Standardized Differences (GSD) % --- Covariate       Pre-GSD     Post-GSD -------------------------------------- age             25.8307       2.7128 sexf           -14.3555      -0.2983 ascites          9.3867      -3.5472 hepato         -17.3835       1.8195 spiders          1.8523       2.3435 edema           10.5640       3.7977 bili           -16.2393      -2.4130 chol            -4.3460      -0.6896 albumin        -10.7653       1.5674 copper           5.7695       3.1788 alk.phos         1.8797       1.2826 ast             -8.1487       2.3462 trig            -3.5608       1.7385 platelet        -7.8802      -3.8991 protime        -14.1917      -2.1593 stage          -16.0707      -2.5238  --- Survival Difference Delta(t) = S1(t) - S0(t) ---  Grid of evaluation times:  time        S1        S0        diff          se      ci_low     ci_high  3170 0.4182155 0.5074675 -0.08925205 0.004087976 -0.09726449 -0.08123962 log.fit <- glm(   treatment ~ age + education + black + hispanic + married + nodegree + re74 + re75,   data = lalonde,   family = binomial() )  ps_log <- log.fit$fitted.values Tr <- lalonde$treatment Z <- lalonde[, c(\"age\", \"education\", \"black\", \"hispanic\", \"married\", \"nodegree\", \"re74\", \"re75\")]  ## Compute GSD gsd_log <- gsd(   Z = Z,   Tr = Tr,   ps = ps_log )  gsd_log age  education      black   hispanic    married   nodegree       re74 -14.947443  12.094698  10.175575   1.447039 -19.351822 -11.262428 -25.978241       re75 -16.354046 ## Calculate ATE wt_log <- 1/(ps_log*Tr+(1-Tr)*(1-ps_log)) est_effect(Y = lalonde$re78, Tr = Tr, wt = wt_log) [1] 224.6763"},{"path":"/articles/tutorial.html","id":"evaluating-the-estimated-propensity-scores","dir":"Articles","previous_headings":"","what":"Evaluating the Estimated Propensity Scores","title":"Tutorial for LBCNet pacakge","text":"fitting LBC-Net model obtaining propensity scores, next step evaluate well scores satisfy key assumptions required causal inference, overlap covariate balance. section demonstrates use LBC-Net’s diagnostic plots assess quality estimated scores. mirror histogram shows distribution propensity scores treated control groups. helps assess overlap (common support) assumption, critical valid causal comparisons. can generate plot directly fitted lbc_net object follows:  sample size relatively small, reasonable overlap groups across much propensity score range. larger datasets, overlap may even clearer, current plot suggests assumption adequately met. mirror_hist() function can also used set propensity scores specifying ps Tr. example, propensity scores logistic regression model mirror_hist(ps = ps_log, Tr = Tr). fitting LBC-Net model, important evaluate whether estimated propensity scores satisfy key theoretical properties: calibration covariate balance. evaluations help assess quality propensity score model ability support valid causal inference. local calibration check assesses whether estimated propensity scores accurately reflect probability treatment assignment. use plot_calib() function visualize calibration. well-calibrated model fitted line closely follow 45-degree line, indicating predicted probabilities match observed treatment rates across score range.  case, due small sample size limited overlap Lalonde dataset, observe deviation 45-degree line, particularly middle range propensity scores. suggests LBC-Net performs reasonably well, achieving perfect calibration smaller samples poor overlap remains challenging. local balance check evaluates whether covariates balanced treatment groups across range propensity scores. use lsd() function calculate Local Standardized Differences (LSD) summarize across covariates.  summary(lsd.fit) function provides mean LSD covariate, plot(lsd.fit) visualizes local balance across entire score range. default plot shows boxplots summarizing variation local balance across covariates (cov = “”). focus specific covariate, age, can specify directly cov = \"age\". prefer remove boxplots focus local balance curves, can suppress setting box.loc = NULL. example, LBC-Net maintains local standardized differences generally 5%5\\% across full range propensity scores, suggesting good local balance. comparison, can evaluate local balance calibration propensity scores estimated traditional logistic regression model.   Compared LBC-Net, logistic regression shows larger global local imbalance, higher LSD values severe deviations calibration plot. results highlight advantage LBC-Net achieving better local balance calibration, particularly datasets challenging overlap sample size conditions.","code":"mirror_hist(lbc_net.fit) plot_calib(lbc_net.fit) lsd.fit <- lsd(lbc_net.fit) summary(lsd.fit) Call:  function (x, ...)  UseMethod(\"formula\") Sample Size: 614  | Number of Covariates: 8 Treated: 185  | Control: 429 Estimand: ATE (Average Treatment Effect)  --- Local Balance (LSD) % --- Max LSD:   6.5110 Mean LSD:  2.8801  Covariates    LSD % -------------------- age          4.7450 education    4.0238 black        4.8189 hispanic     2.0604 married      2.3148 nodegree     2.7860 re74         1.4534 re75         0.8387 plot(lsd.fit) plot_calib(Tr = Tr, ps = ps_log) lsd.fit.log <- lsd(Z = Z, Tr = Tr, ps = ps_log) summary(lsd.fit.log) Call:  function (x, ...)  UseMethod(\"formula\") Sample Size: 614  | Number of Covariates: 8 Treated: 185  | Control: 429 Estimand: ATE (Average Treatment Effect)  --- Local Balance (LSD) % --- Max LSD:   77.7346 Mean LSD:  10.2577  Covariates    LSD % -------------------- age         16.3696 education    9.0942 black        6.0572 hispanic     2.9699 married     13.7013 nodegree    12.7773 re74        11.7533 re75         9.3384 plot(lsd.fit.log)"},{"path":"/articles/tutorial.html","id":"local-calibration-and-local-balance","dir":"Articles","previous_headings":"","what":"Local Calibration and Local Balance","title":"Tutorial for LBCNet pacakge","text":"fitting LBC-Net model, important evaluate whether estimated propensity scores satisfy key theoretical properties: calibration covariate balance. evaluations help assess quality propensity score model ability support valid causal inference. local calibration check assesses whether estimated propensity scores accurately reflect probability treatment assignment. use plot_calib() function visualize calibration. well-calibrated model fitted line closely follow 45-degree line, indicating predicted probabilities match observed treatment rates across score range.  case, due small sample size limited overlap Lalonde dataset, observe deviation 45-degree line, particularly middle range propensity scores. suggests LBC-Net performs reasonably well, achieving perfect calibration smaller samples poor overlap remains challenging. local balance check evaluates whether covariates balanced treatment groups across range propensity scores. use lsd() function calculate Local Standardized Differences (LSD) summarize across covariates.  summary(lsd.fit) function provides mean LSD covariate, plot(lsd.fit) visualizes local balance across entire score range. default plot shows boxplots summarizing variation local balance across covariates (cov = “”). focus specific covariate, age, can specify directly cov = \"age\". prefer remove boxplots focus local balance curves, can suppress setting box.loc = NULL. example, LBC-Net maintains local standardized differences generally 5%5\\% across full range propensity scores, suggesting good local balance. comparison, can evaluate local balance calibration propensity scores estimated traditional logistic regression model.   Compared LBC-Net, logistic regression shows larger global local imbalance, higher LSD values severe deviations calibration plot. results highlight advantage LBC-Net achieving better local balance calibration, particularly datasets challenging overlap sample size conditions.","code":"plot_calib(lbc_net.fit) lsd.fit <- lsd(lbc_net.fit) summary(lsd.fit) Call:  function (x, ...)  UseMethod(\"formula\") Sample Size: 614  | Number of Covariates: 8 Treated: 185  | Control: 429 Estimand: ATE (Average Treatment Effect)  --- Local Balance (LSD) % --- Max LSD:   6.5110 Mean LSD:  2.8801  Covariates    LSD % -------------------- age          4.7450 education    4.0238 black        4.8189 hispanic     2.0604 married      2.3148 nodegree     2.7860 re74         1.4534 re75         0.8387 plot(lsd.fit) plot_calib(Tr = Tr, ps = ps_log) lsd.fit.log <- lsd(Z = Z, Tr = Tr, ps = ps_log) summary(lsd.fit.log) Call:  function (x, ...)  UseMethod(\"formula\") Sample Size: 614  | Number of Covariates: 8 Treated: 185  | Control: 429 Estimand: ATE (Average Treatment Effect)  --- Local Balance (LSD) % --- Max LSD:   77.7346 Mean LSD:  10.2577  Covariates    LSD % -------------------- age         16.3696 education    9.0942 black        6.0572 hispanic     2.9699 married     13.7013 nodegree    12.7773 re74        11.7533 re75         9.3384 plot(lsd.fit.log)"},{"path":"/articles/tutorial.html","id":"chat-balance-covariate-distribution","dir":"Articles","previous_headings":"","what":"Chat: Balance Covariate Distribution","title":"Tutorial for LBCNet pacakge","text":"plot_cov_bal() function shows distribution specific covariate treated control groups, weighting. allows visually assess whether LBC-Net improved covariate balance applying weights. example, examine balance covariate age:  default, plot displays weighted distribution using kernel density estimation. prefer view unweighted distribution, can set use_weights = FALSE. Additionally, can display distribution histograms instead density plots using plot_type = \"hist\". categorical variables, function automatically display histograms. cases, binary variables well balanced weighting. However, categorical variables two levels, create dummy (one-hot encoded) variables fitting model ensure proper balance across categories. shown plot, method designed balance first moment (mean) covariates. However, may fully balance entire distribution, particularly continuous variables age. address , one option categorize continuous variables treat categorical model. can improve balance across categories, rather just matching means. , categorize age 3 groups education 4 groups. create dummy variables categories fit LBC-Net model using newly processed data. fitting new model, can review updated balance summaries compare covariate distributions across methods.","code":"plot_cov_bal(lbc_net.fit, cov = \"age\", use_weights = TRUE) library(janitor)  # Categorize age (3 groups) and education (4 groups) lalonde$age_group <- cut(lalonde$age, breaks = c(16, 23, 30, 37, 44, 55), include.lowest = TRUE) lalonde$education_group <- cut(lalonde$education, breaks = c(0, 6, 12, 16, 18), include.lowest = TRUE)  # Create dummy variables age_dummies <- model.matrix(~ age_group - 1, data = lalonde) education_dummies <- model.matrix(~ education_group - 1, data = lalonde)  # Clean names colnames(age_dummies) <- janitor::make_clean_names(colnames(age_dummies)) colnames(education_dummies) <- janitor::make_clean_names(colnames(education_dummies))  # Combine data lalonde_processed <- cbind(   lalonde[, !(names(lalonde) %in% c(\"age\", \"education\", \"age_group\", \"education_group\"))],   age_dummies,   education_dummies ) colnames(lalonde_processed) <- janitor::make_clean_names(colnames(lalonde_processed))  # Fit LBC-Net model lbc_net.fit.new <- lbc_net(   data = lalonde_processed,   formula = treatment ~ . - re78,   max_epochs = 15000,   rho = 0.4 ) ⚠️ Stopping criterion not met at max epochs. Try increasing `max_epochs` or adjusting `lsd_threshold` for better convergence. ✅ LBC-Net training completed successfully. plot_cov_bal(Z = Z, Tr = Tr, wt = lbc_net.fit.new$weights, cov = \"age\", use_weights = TRUE) plot_cov_bal(Z = Z, Tr = Tr, wt = wt_log, cov = \"age\", use_weights = TRUE)"},{"path":"/articles/tutorial.html","id":"reference","dir":"Articles","previous_headings":"","what":"Reference","title":"Tutorial for LBCNet pacakge","text":"Rosenbaum, P. R. Rubin, D. B. (1983). central role propensity score observational studies causal effects. Biometrika, 70(1):41–55. Zubizarreta J, Li Y, Kim K (2024). sbw: Stable Balancing Weights Causal Inference Missing Data. R package version 1.1.9, https://CRAN.R-project.org/package=sbw.","code":""},{"path":"/articles/tutorial.html","id":"contribute-and-feedback","dir":"Articles","previous_headings":"","what":"Contribute and Feedback","title":"Tutorial for LBCNet pacakge","text":"welcome contributions, feedback, suggestions! - Report bugs request features GitHub Issues page. - Fork repository submit pull requests help improve LBCNet!","code":""},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Maosen Peng. Author, maintainer.           Department Biostatistics, University Texas MD Anderson Cancer Center,Department Biostatistics Data Science, University Texas School Public Health Yan Li. Author.           Department Quantitative Health Sciences, Mayo Clinic Chong Wu. Author.           Department Biostatistics, University Texas MD Anderson Cancer Center Liang Li. Author.           Department Biostatistics, University Texas MD Anderson Cancer Center","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Peng M, Li Y, Wu C, Li L (2025). LBCNet: Local Balance Calibration implemented Neural Networks propensity score estimation. R package version 0.1.1.","code":"@Manual{,   title = {LBCNet: Local Balance with Calibration implemented by Neural Networks for propensity score estimation},   author = {Maosen Peng and Yan Li and Chong Wu and Liang Li},   year = {2025},   note = {R package version 0.1.1}, }"},{"path":[]},{"path":"/index.html","id":"description","dir":"","previous_headings":"","what":"Description","title":"Local Balance with Calibration implemented by Neural Networks for propensity score estimation","text":"LBCNet implements LBC-Net estimating propensity scores, introduced “Local Balance Calibration Nonparametric Propensity Score Estimation” package proposes novel propensity score weighting method based two fundamental conditions: local balance, ensures conditional independence covariates treatment assignment across dense grid balancing scores, local calibration, guarantees balancing scores mapped true propensity scores. leveraging neural network, LBCNet develops nonparametric propensity score model effectively optimizes covariate balance, minimizes bias, stabilizes inverse probability treatment weights (IPTW). addition estimating ATE ATT binary treatments, LBCNet provides unified interface : Variance estimation: plug-influence functions, model-based uncertainty quantification, robust standard errors IPTW LBC-Net–based estimators. Survival estimands: risk difference survival difference fixed time ( t ), support IPW–adjusted Kaplan–Meier Nelson–Aalen estimators. package integrates R Python modules deliver scalable, easy--use workflow modern causal inference research, including treatment effect estimation, sensitivity analysis, evaluation covariate balance learned propensity score models.","code":""},{"path":"/index.html","id":"installing-python","dir":"","previous_headings":"","what":"Installing Python","title":"Local Balance with Calibration implemented by Neural Networks for propensity score estimation","text":"LBCNet requires Python installed system. can download install Python official website: Download Python Make sure install Python 3.8 - 3.11, versions 3.12 may cause compatibility issues dependencies.","code":""},{"path":"/index.html","id":"verifying-python-installation","dir":"","previous_headings":"Installing Python","what":"Verifying Python Installation","title":"Local Balance with Calibration implemented by Neural Networks for propensity score estimation","text":"installing Python, open terminal command prompt check Python installed correctly running: Python installed correctly, see output similar : Windows users, ensure Python added system PATH installation. encounter issues, refer official Python documentation troubleshooting.","code":"python --version python3 --version Python 3.10.12"},{"path":"/index.html","id":"first-time-setup-installing-and-configuring-reticulate-in-r","dir":"","previous_headings":"","what":"First-Time Setup: Installing and Configuring Reticulate in R","title":"Local Balance with Calibration implemented by Neural Networks for propensity score estimation","text":"LBCNet uses reticulate package interface R Python. first time use LBCNet, must set reticulate configure Python. setup complete, won’t need configure every time.","code":""},{"path":"/index.html","id":"id_1-install-reticulate-in-r","dir":"","previous_headings":"First-Time Setup: Installing and Configuring Reticulate in R","what":"1. Install reticulate in R","title":"Local Balance with Calibration implemented by Neural Networks for propensity score estimation","text":"haven’t installed reticulate yet, run: detailed installation setup instructions, visit Reticulate Documentation.","code":"install.packages(\"reticulate\")"},{"path":"/index.html","id":"id_2-verify-python-installation-in-r","dir":"","previous_headings":"First-Time Setup: Installing and Configuring Reticulate in R","what":"2. Verify Python Installation in R","title":"Local Balance with Calibration implemented by Neural Networks for propensity score estimation","text":"installing reticulate, load check Python version detected: reticulate detects correct Python version, can skip next step. , must manually specify correct Python path.","code":"available_pythons <- unique(c(   Sys.which(\"python\"),   Sys.which(\"python3\"),   reticulate::py_discover_config()$python ))  available_pythons <- available_pythons[nzchar(available_pythons)]  # Remove empty results print(available_pythons)  # Check available virtual and Conda environments reticulate::virtualenv_list() reticulate::conda_list()"},{"path":"/index.html","id":"id_3-first-time-python-setup-choose-one-of-the-following-options","dir":"","previous_headings":"First-Time Setup: Installing and Configuring Reticulate in R","what":"3. First-Time Python Setup: Choose One of the Following Options","title":"Local Balance with Calibration implemented by Neural Networks for propensity score estimation","text":"multiple ways configure Python reticulate. Choose one method best suits setup. Option 1: Use System Python (Recommended Servers & Clusters) Python installed globally system, reticulate detect automatically. manually specify path: ensures stability using known, system-managed Python installation. Using system Python may cause conflicts R packages require different dependencies. Option 2: Create Virtual Environment (Recommended) virtual environment (venv) isolates Python dependencies, ensuring LBCNet runs without conflicts. Create activate virtual environment: Best : Ensuring package isolation avoiding conflicts Python versions. Option 3: Use Conda Environment Conda installed, can use Conda-managed Python environment. Best : Users already use Conda manage Python dependencies.","code":"## Set the Python Path for the Entire R Session  ## Best for: Servers, clusters, and users who manage Python separately. Sys.setenv(RETICULATE_PYTHON = \"/path/to/python\")  # Adjust based on your system reticulate::py_discover_config() ## Set Python for the Current R Session Only ## Best for: Local machines where Python paths may change frequently. reticulate::use_python(\"/path/to/python\", required = TRUE) reticulate::py_config() reticulate::virtualenv_create(\"r-lbcnet\")  # Create virtual environment reticulate::use_virtualenv(\"r-lbcnet\", required = TRUE)  # Activate virtual environment reticulate::conda_create(\"r-lbcnet\", packages = c(\"python=3.11\")) reticulate::use_condaenv(\"r-lbcnet\", required = TRUE)"},{"path":"/index.html","id":"id_4-first-time-installation-of-required-python-packages","dir":"","previous_headings":"First-Time Setup: Installing and Configuring Reticulate in R","what":"4. First-Time Installation of Required Python Packages","title":"Local Balance with Calibration implemented by Neural Networks for propensity score estimation","text":"Python configured, need install required dependencies. Run one following: Verify installation: detailed package intall instructions, visit Package Install.","code":"reticulate::py_install(c(\"torch\", \"numpy\", \"pandas\", \"tqdm\"), envname = \"r-lbcnet\") system(\"pip install torch numpy pandas tqdm\") py_run_string(\"import numpy; print(numpy.__version__)\") py_run_string(\"import torch; print(torch.__version__)\")"},{"path":"/index.html","id":"id_5-common-issues-and-fixes","dir":"","previous_headings":"First-Time Setup: Installing and Configuring Reticulate in R","what":"5. Common Issues and Fixes","title":"Local Balance with Calibration implemented by Neural Networks for propensity score estimation","text":"Multiple Python Installations: multiple versions Python installed, may need specify correct path using use_python(). Administrator Privileges: installations require running R administrator privileges install dependencies. Dependency Restrictions: Certain Python packages may work latest versions Python (e.g., Python ≥3.12). Python version mismatch: Run py_config() ensure Python set correct version. Module found (e.g., torch found): Run py_install(\"torch\") install missing dependencies try py_require(\"torch\"). Failed initialize Python: Restart R session (Session > Restart R) rerun use_virtualenv() use_condaenv(). commands execute without errors display package versions, installation successful.","code":""},{"path":"/index.html","id":"install-lbcnet","dir":"","previous_headings":"","what":"Install LBCNet","title":"Local Balance with Calibration implemented by Neural Networks for propensity score estimation","text":"","code":"devtools::install_github(\"MaosenPeng1/LBCNet\") remotes::install_github(\"MaosenPeng1/LBCNet\")"},{"path":"/index.html","id":"getting-started","dir":"","previous_headings":"","what":"Getting Started","title":"Local Balance with Calibration implemented by Neural Networks for propensity score estimation","text":"Explore package easy--follow resources: Simulated Example quick demo illustrating key package functions. Comprehensive Tutorial step--step guide covering model fitting, diagnostics, survival extensions.","code":""},{"path":"/index.html","id":"acknowledgement","dir":"","previous_headings":"","what":"Acknowledgement","title":"Local Balance with Calibration implemented by Neural Networks for propensity score estimation","text":"project partially supported theCancer Prevention & Research Institute Texas (CPRIT) project RP210130.","code":""},{"path":"/index.html","id":"need-help","dir":"","previous_headings":"","what":"Need Help?","title":"Local Balance with Calibration implemented by Neural Networks for propensity score estimation","text":"GitHub Repository:https://github.com/MaosenPeng1/LBCNet Report Issues Suggest Features:https://github.com/MaosenPeng1/LBCNet/issues Contact:mpeng1@mdanderson.org welcome feedback, bug reports, contributions!","code":""},{"path":"/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU General Public License","title":"GNU General Public License","text":"Version 3, 29 June 2007Copyright © 2007 Free Software Foundation, Inc. <http://fsf.org/> Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU General Public License","text":"GNU General Public License free, copyleft license software kinds works. licenses software practical works designed take away freedom share change works. contrast, GNU General Public License intended guarantee freedom share change versions program–make sure remains free software users. , Free Software Foundation, use GNU General Public License software; applies also work released way authors. can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. protect rights, need prevent others denying rights asking surrender rights. Therefore, certain responsibilities distribute copies software, modify : responsibilities respect freedom others. example, distribute copies program, whether gratis fee, must pass recipients freedoms received. must make sure , , receive can get source code. must show terms know rights. Developers use GNU GPL protect rights two steps: (1) assert copyright software, (2) offer License giving legal permission copy, distribute /modify . developers’ authors’ protection, GPL clearly explains warranty free software. users’ authors’ sake, GPL requires modified versions marked changed, problems attributed erroneously authors previous versions. devices designed deny users access install run modified versions software inside , although manufacturer can . fundamentally incompatible aim protecting users’ freedom change software. systematic pattern abuse occurs area products individuals use, precisely unacceptable. Therefore, designed version GPL prohibit practice products. problems arise substantially domains, stand ready extend provision domains future versions GPL, needed protect freedom users. Finally, every program threatened constantly software patents. States allow patents restrict development use software general-purpose computers, , wish avoid special danger patents applied free program make effectively proprietary. prevent , GPL assures patents used render program non-free. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"/LICENSE.html","id":"id_0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions","title":"GNU General Public License","text":"“License” refers version 3 GNU General Public License. “Copyright” also means copyright-like laws apply kinds works, semiconductor masks. “Program” refers copyrightable work licensed License. licensee addressed “”. “Licensees” “recipients” may individuals organizations. “modify” work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called “modified version” earlier work work “based ” earlier work. “covered work” means either unmodified Program work based Program. “propagate” work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. “convey” work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays “Appropriate Legal Notices” extent includes convenient prominently visible feature (1) displays appropriate copyright notice, (2) tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"/LICENSE.html","id":"id_1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code","title":"GNU General Public License","text":"“source code” work means preferred form work making modifications . “Object code” means non-source form work. “Standard Interface” means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. “System Libraries” executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. “Major Component”, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . “Corresponding Source” work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work’s System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"/LICENSE.html","id":"id_2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions","title":"GNU General Public License","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"/LICENSE.html","id":"id_3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users’ Legal Rights From Anti-Circumvention Law","title":"GNU General Public License","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work’s users, third parties’ legal rights forbid circumvention technological measures.","code":""},{"path":"/LICENSE.html","id":"id_4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies","title":"GNU General Public License","text":"may convey verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"/LICENSE.html","id":"id_5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions","title":"GNU General Public License","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: ) work must carry prominent notices stating modified , giving relevant date. b) work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 “keep intact notices”. c) must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . d) work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called “aggregate” compilation resulting copyright used limit access legal rights compilation’s users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"/LICENSE.html","id":"id_6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms","title":"GNU General Public License","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: ) Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. b) Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either (1) copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, (2) access copy Corresponding Source network server charge. c) Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. d) Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server (operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. e) Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. “User Product” either (1) “consumer product”, means tangible personal property normally used personal, family, household purposes, (2) anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, “normally used” refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. “Installation Information” User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"/LICENSE.html","id":"id_7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms","title":"GNU General Public License","text":"“Additional permissions” terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: ) Disclaiming warranty limiting liability differently terms sections 15 16 License; b) Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; c) Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; d) Limiting use publicity purposes names licensors authors material; e) Declining grant rights trademark law use trade names, trademarks, service marks; f) Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered “restrictions” within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"/LICENSE.html","id":"id_8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination","title":"GNU General Public License","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated () provisionally, unless copyright holder explicitly finally terminates license, (b) permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"/LICENSE.html","id":"id_9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies","title":"GNU General Public License","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"/LICENSE.html","id":"id_10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients","title":"GNU General Public License","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. “entity transaction” transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party’s predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"/LICENSE.html","id":"id_11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents","title":"GNU General Public License","text":"“contributor” copyright holder authorizes use License Program work Program based. work thus licensed called contributor’s “contributor version”. contributor’s “essential patent claims” patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, “control” includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor’s essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, “patent license” express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). “grant” patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either (1) cause Corresponding Source available, (2) arrange deprive benefit patent license particular work, (3) arrange, manner consistent requirements License, extend patent license downstream recipients. “Knowingly relying” means actual knowledge , patent license, conveying covered work country, recipient’s use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license “discriminatory” include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license () connection copies covered work conveyed (copies made copies), (b) primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"/LICENSE.html","id":"id_12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others’ Freedom","title":"GNU General Public License","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"/LICENSE.html","id":"id_13-use-with-the-gnu-affero-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Use with the GNU Affero General Public License","title":"GNU General Public License","text":"Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU Affero General Public License single combined work, convey resulting work. terms License continue apply part covered work, special requirements GNU Affero General Public License, section 13, concerning interaction network apply combination .","code":""},{"path":"/LICENSE.html","id":"id_14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License","title":"GNU General Public License","text":"Free Software Foundation may publish revised /new versions GNU General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU General Public License “later version” applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU General Public License can used, proxy’s public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"/LICENSE.html","id":"id_15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty","title":"GNU General Public License","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"/LICENSE.html","id":"id_16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability","title":"GNU General Public License","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"/LICENSE.html","id":"id_17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16","title":"GNU General Public License","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee. END TERMS CONDITIONS","code":""},{"path":"/LICENSE.html","id":"how-to-apply-these-terms-to-your-new-programs","dir":"","previous_headings":"","what":"How to Apply These Terms to Your New Programs","title":"GNU General Public License","text":"develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively state exclusion warranty; file least “copyright” line pointer full notice found. Also add information contact electronic paper mail. program terminal interaction, make output short notice like starts interactive mode: hypothetical commands show w show c show appropriate parts General Public License. course, program’s commands might different; GUI interface, use “box”. also get employer (work programmer) school, , sign “copyright disclaimer” program, necessary. information , apply follow GNU GPL, see <http://www.gnu.org/licenses/>. GNU General Public License permit incorporating program proprietary programs. program subroutine library, may consider useful permit linking proprietary applications library. want , use GNU Lesser General Public License instead License. first, please read <http://www.gnu.org/philosophy/--lgpl.html>.","code":"<one line to give the program's name and a brief idea of what it does.> Copyright (C) <year>  <name of author>  This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.  This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.  You should have received a copy of the GNU General Public License along with this program.  If not, see <http://www.gnu.org/licenses/>. <program>  Copyright (C) <year>  <name of author> This program comes with ABSOLUTELY NO WARRANTY; for details type 'show w'. This is free software, and you are welcome to redistribute it under certain conditions; type 'show c' for details."},{"path":"/reference/est_effect.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate Causal Effects — est_effect","title":"Estimate Causal Effects — est_effect","text":"generic function estimates causal effects different object types. automatically dispatches appropriate method based class `object`.","code":""},{"path":"/reference/est_effect.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate Causal Effects — est_effect","text":"","code":"est_effect(object, Y, ...)"},{"path":"/reference/est_effect.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate Causal Effects — est_effect","text":"object object calculate effects. Y Numeric vector observed outcomes. ... Additional arguments (ignored).","code":""},{"path":"/reference/est_effect.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate Causal Effects — est_effect","text":"Returns values effects.","code":""},{"path":"/reference/est_effect.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimate Causal Effects — est_effect","text":"function uses S3 method dispatching call appropriate method based object type. designed estimating causal effects settings continuous binary outcomes. survival outcomes, users apply appropriate survival analysis models, weighted Cox model time--event estimation methods. `lbc_net` objects, see est_effect.lbc_net details. Additional object types may supported future.","code":""},{"path":"/reference/est_effect.lbc_net.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate Weighted Outcomes, ATE, or ATT for an lbc_net object — est_effect.lbc_net","title":"Estimate Weighted Outcomes, ATE, or ATT for an lbc_net object — est_effect.lbc_net","text":"Computes weighted mean outcome, average treatment effect (ATE), average treatment effect treated (ATT). Y must provided, users can either supply `lbc_net` object (automatically extracts weights treatment assignments) manually provide `Tr` `wt`.","code":""},{"path":"/reference/est_effect.lbc_net.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate Weighted Outcomes, ATE, or ATT for an lbc_net object — est_effect.lbc_net","text":"","code":"# S3 method for class 'lbc_net' est_effect(object = NULL, Y, Tr = NULL, wt = NULL, type = \"ATE\", ...)"},{"path":"/reference/est_effect.lbc_net.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate Weighted Outcomes, ATE, or ATT for an lbc_net object — est_effect.lbc_net","text":"object Optional. object class `\"lbc_net\"` generated lbc_net. provided, `Tr` `wt` extracted automatically. Y Numeric vector observed outcomes. Tr Optional. Numeric binary vector (0/1) indicating treatment assignment. Required `object` NULL. wt Optional. Numeric vector inverse probability weights. Required `object` NULL. type Character string specifying desired estimate. default `\"ATE\"`, computes average treatment effect. Setting `type = \"ATT\"` estimates average treatment effect treated, `type = \"Y\"` returns weighted mean outcome treated group (`Tr = 1`). object provided, estimate consistent object's specification, users can also select `\"Y\"`. ... Additional arguments passed specific method.","code":""},{"path":"/reference/est_effect.lbc_net.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate Weighted Outcomes, ATE, or ATT for an lbc_net object — est_effect.lbc_net","text":"numeric value representing estimated quantity.","code":""},{"path":"/reference/est_effect.lbc_net.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimate Weighted Outcomes, ATE, or ATT for an lbc_net object — est_effect.lbc_net","text":"designed estimating causal effects settings continuous binary outcomes. survival outcomes, users apply appropriate survival analysis models, weighted Cox model time--event estimation methods. Inverse Probability Weighting (IPW) used estimate treatment effect, weight subject \\(\\) : $$ W_i = \\frac{\\omega^*(p_i)}{ T_i p_i + (1 - T_i)(1 - p_i) }. $$ frequency weight function \\(\\omega^{*}(p_i)\\) determines target population: setting \\(\\omega^{*}(p_i) = 1\\) yields Average Treatment Effect (ATE), choosing \\(\\omega^{*}(p_i) = p_i\\) results Average Treatment Effect Treated (ATT). population-level treatment effect estimated : $$ \\Delta = \\frac{E(\\omega^*(p_i) \\Delta_i)}{E(\\omega^*(p_i))}, $$ \\(\\Delta_i = E[Y_i(1) - Y_i(0) \\mid \\mathbf{Z}_i]\\) represents individual conditional treatment effect. inverse probability weighted (IPW) estimator ATE ATT follows: $$ \\hat{\\Delta} = \\frac{\\sum_{=1}^N T_i W_i Y_i}{\\sum_{=1}^N T_i W_i} - \\frac{\\sum_{=1}^N (1-T_i) W_i Y_i}{\\sum_{=1}^N (1-T_i) W_i}. $$","code":""},{"path":"/reference/est_effect.lbc_net.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Estimate Weighted Outcomes, ATE, or ATT for an lbc_net object — est_effect.lbc_net","text":"function compute variance estimates due computational cost.   Users can obtain variance estimates via bootstrapping, ensuring inverse probability weights (`wt`)   recomputed using `lbc_net()` resampled dataset. improve efficiency, consider using parallel computing   `foreach` `doParallel` package.","code":""},{"path":"/reference/est_effect.lbc_net.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate Weighted Outcomes, ATE, or ATT for an lbc_net object — est_effect.lbc_net","text":"","code":"# Simulated example set.seed(123) Y <- rnorm(100)  # Random outcome Tr <- rbinom(100, 1, 0.5)  # Random treatment assignment wt <- runif(100, 0.5, 1.5)  # Random inverse probability weights  # Manually specify Tr and wt est_effect(Y = Y, Tr = Tr, wt = wt, type = \"Y\") #> [1] 0.1200686 est_effect(Y = Y, Tr = Tr, wt = wt, type = \"ATE\") #> [1] 0.1134007 est_effect(Y = Y, Tr = Tr, wt = wt, type = \"ATT\") #> [1] 0.1009665  if (FALSE) { # \\dontrun{ # Use an lbc_net object model <- lbc_net(data = data, formula = Tr ~ X1 + X2 + X3 + X4) est_effect(object = model, Y, type = \"Y\")  } # }"},{"path":"/reference/getLBC.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Components from an Object — getLBC","title":"Extract Components from an Object — getLBC","text":"generic function used extract components different object types. function dispatches appropriate method based class `object`, ensuring users can retrieve key model outputs supported objects `\"lbc_net\"` `lsd`.","code":""},{"path":"/reference/getLBC.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Components from an Object — getLBC","text":"","code":"getLBC(object, name)"},{"path":"/reference/getLBC.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Components from an Object — getLBC","text":"object object extract components. name name(s) component(s) extract.","code":""},{"path":"/reference/getLBC.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Components from an Object — getLBC","text":"requested component(s), based specific method object's class.","code":""},{"path":"/reference/getLBC.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract Components from an Object — getLBC","text":"function uses S3 method dispatching call appropriate method based object type. example: `object` class `\"lbc_net\"` `\"lsd\"`, see getLBC.lbc_net getLBC.lsd details. Additional object types may supported future.","code":""},{"path":"/reference/getLBC.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract Components from an Object — getLBC","text":"","code":"if (FALSE) { # \\dontrun{ fit <- lbc_net(data = my_data, formula = Tr ~ X1 + X2) getLBC(fit, \"fitted.values\")  # Extract propensity scores } # }"},{"path":"/reference/getLBC.lbc_net.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Components from an lbc_net Object — getLBC.lbc_net","title":"Extract Components from an lbc_net Object — getLBC.lbc_net","text":"Retrieves specific components `lbc_net` object. function provides structured way access key results, ensuring users retrieve correct model components.","code":""},{"path":"/reference/getLBC.lbc_net.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Components from an lbc_net Object — getLBC.lbc_net","text":"","code":"# S3 method for class 'lbc_net' getLBC(object, name = \"fitted.values\")"},{"path":"/reference/getLBC.lbc_net.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Components from an lbc_net Object — getLBC.lbc_net","text":"object object class `\"lbc_net\"`, generated lbc_net. name character vector specifying name(s) component(s) extract.   name = \"\", named list available components returned.   Available options include: \"fitted.values\" Estimated propensity scores. \"weights\" Inverse probability weights (IPW). \"loss\" final total loss value. \"lsd_train\" list containing key local standardized mean difference (LSD) values       recorded training: lsd_max – Maximum local standardized mean difference observed training. lsd_mean – Mean local standardized mean difference observed training. complete LSD profile can computed using function lsd(). \"parameters\" Model hyperparameters hidden_dim, L, vae_lr, lr,       weight_decay, balance_lambda, epsilon. \"stopping_criteria\" Stopping parameters including lsd_threshold,       rolling_window, max_epochs. \"seed\" Random seed used reproducibility. \"call\" matched function call. \"formula\" Formula used (applicable). \"Z\" Covariate matrix used. \"Tr\" Treatment assignment vector. \"ck\" Kernel center values used. \"h\" Bandwidth values used. \"K\" Number kernel points. \"rho\" Span parameter used construct bandwidths. \"ate_flag\" ATE ATT flag used loss. \"kernel\" Kernel used define local neighbourhoods. \"ps_logistic\" Propensity scores fitted via logistic regression. \"estimand\" Target estimand ATE, ATT, Y. \"effect\" Estimated causal effect (computed). \"se\" Estimated standard error (computed). \"ci\" Confidence interval estimated effect.","code":""},{"path":"/reference/getLBC.lbc_net.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Components from an lbc_net Object — getLBC.lbc_net","text":"requested component(s) `lbc_net` object. Default returns \"fitted.values\". multiple names provided `name = \"\"`, named list components returned.","code":""},{"path":"/reference/getLBC.lbc_net.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract Components from an lbc_net Object — getLBC.lbc_net","text":"","code":"if (FALSE) { # \\dontrun{ model <- lbc_net(data = data, formula = Tr ~ X1 + X2 + X3 + X4) getLBC(model, \"fitted.values\")  # Extract propensity scores getLBC(model, c(\"fitted.values\", \"weights\"))  # Extract multiple components getLBC(model, \"ALL\")  # Extract all components as a named list } # }"},{"path":"/reference/getLBC.lbc_net_surv.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Components from an lbc_net_surv Object — getLBC.lbc_net_surv","title":"Extract Components from an lbc_net_surv Object — getLBC.lbc_net_surv","text":"Retrieves specific components \"lbc_net_surv\" object. function provides structured way access key results survival outcomes, ensuring users retrieve correct model components.","code":""},{"path":"/reference/getLBC.lbc_net_surv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Components from an lbc_net_surv Object — getLBC.lbc_net_surv","text":"","code":"# S3 method for class 'lbc_net_surv' getLBC(object, name = \"fitted.values\")"},{"path":"/reference/getLBC.lbc_net_surv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Components from an lbc_net_surv Object — getLBC.lbc_net_surv","text":"object object class \"lbc_net_surv\", generated lbc_net_surv. name character vector specifying name(s) component(s)   extract. name = \"\", entire object (named list)   returned. Available options include: \"fitted.values\" Estimated propensity scores. \"weights\" Inverse probability weights (IPW) calculated       \\(1 / (\\hat e(X) + (1-)\\{1-\\hat e(X)\\})\\). \"loss\" Final total training loss value LBC-Net. \"lsd_train\" list containing key local standardized mean       difference (LSD) values recorded training: lsd_max – Maximum LSD final epoch. lsd_mean – Mean LSD final epoch. Note: full local balance profile can recomputed using       lsd evaluation. \"parameters\" Model hyperparameters including (typically)       hidden_dim, num_hidden_layers, vae_lr, lr,       weight_decay, balance_lambda, epsilon. \"stopping_criteria\" Stopping parameters including       lsd_threshold, rolling_window, max_epochs. \"seed\" Random seed used reproducibility. \"call\" matched function call reference. \"formula\" Formula used (applicable). \"Z\" Covariate matrix used. \"Tr\" Treatment assignment vector. \"time\" Event censoring times used survival analysis. \"delta\" Event indicator (1 = event, 0 = censored). \"ck\" Kernel center values used. \"h\" Bandwidth values used. \"K\" Number kernel points. \"rho\" Span value used construct bandwidths. \"kernel\" Kernel used define local neighbourhood. \"ps_logistic\" Propensity scores fitted via logistic regression. \"survival\" list containing survival-related outputs, e.g.,       evaluation times, survival curves S1, S0, survival       differences, variances, confidence intervals.","code":""},{"path":"/reference/getLBC.lbc_net_surv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Components from an lbc_net_surv Object — getLBC.lbc_net_surv","text":"requested component(s) \"lbc_net_surv\" object. single name provided, corresponding component returned directly. multiple names provided, named list returned. name = \"\", full object returned.","code":""},{"path":"/reference/getLBC.lbc_net_surv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract Components from an lbc_net_surv Object — getLBC.lbc_net_surv","text":"","code":"if (FALSE) { # \\dontrun{ fit_surv <- lbc_net_surv(   data    = dat,   formula = Tr ~ X1 + X2,   time    = \"time\",   delta   = \"delta\" ) getLBC(fit_surv, \"survival\")     # Extract survival curves and differences getLBC(fit_surv, c(\"fitted.values\", \"weights\"))  # PS and weights } # }"},{"path":"/reference/getLBC.lsd.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Components from an lsd Object — getLBC.lsd","title":"Extract Components from an lsd Object — getLBC.lsd","text":"Retrieves specific components `lsd` object. function provides structured way access key results, ensuring users retrieve correct model components.","code":""},{"path":"/reference/getLBC.lsd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Components from an lsd Object — getLBC.lsd","text":"","code":"# S3 method for class 'lsd' getLBC(object, name = \"LSD_mean\")"},{"path":"/reference/getLBC.lsd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Components from an lsd Object — getLBC.lsd","text":"object object class `\"lsd\"`, generated lsd. name character vector specifying name(s) component(s) extract. `name = \"\"`, named list available components returned. Available options include: `\"LSD\"` matrix LSD values covariate `ck`. `\"LSD_mean\"` mean absolute LSD value across covariates. `\"LSD_max\"` maximum absolute LSD value. `\"Z\"` Covariate matrix used. `\"Tr\"` Treatment assignment vector. `\"ck\"` Kernel center values used. `\"h\"` Bandwidth values used. `\"K\"` Number kernel points. `\"rho\"` Span values used. `\"ate_flag\"` ATE ATT aim estimate. `\"kernel\"` kernel used define local neibourhood.","code":""},{"path":"/reference/getLBC.lsd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Components from an lsd Object — getLBC.lsd","text":"requested component(s) `lbc_net` object. Default returns \"fitted.values\". multiple names provided `name = \"\"`, named list components returned.","code":""},{"path":"/reference/getLBC.lsd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract Components from an lsd Object — getLBC.lsd","text":"","code":"if (FALSE) { # \\dontrun{ model <- lbc_net(data = data, formula = Tr ~ X1 + X2 + X3 + X4) LSD.fit <- lsd(model) getLBC(LSD.fit, \"LSD\") getLBC(LSD.fit, c(\"LSD\", \"LSD_mean\"))  # Extract multiple components getLBC(LSD.fit, \"ALL\")  # Extract all components as a named list } # }"},{"path":"/reference/gsd.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Global Standardized Mean Difference (GSD) — gsd","title":"Compute Global Standardized Mean Difference (GSD) — gsd","text":"Estimates Global Standardized Mean Difference (GSD), standardized mean difference used assessing balance covariate distributions treatment groups. GSD reported percentage widely used propensity score weighting methods.","code":""},{"path":"/reference/gsd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Global Standardized Mean Difference (GSD) — gsd","text":"","code":"gsd(   object = NULL,   Z = NULL,   Tr = NULL,   ps = NULL,   wt = NULL,   ate_flag = 1,   ... )"},{"path":"/reference/gsd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Global Standardized Mean Difference (GSD) — gsd","text":"object optional object class `\"lbc_net\"`, `Z`, `Tr`, `weights` extracted. Z numeric matrix, data frame, vector covariates. Required `object` provided. Tr numeric vector (0/1) indicating treatment assignment. Required `object` provided. ps numeric vector propensity scores (\\(0 < ps < 1\\)). Used compute weights : $$\\frac{w^*(ps)}{Tr \\cdot ps + (1 - Tr) \\cdot (1 - ps)}.$$ argument ATE must specified: ATE = 1, \\(w^*(ps) = 1\\); ATE = 0, \\(w^*(ps) = ps\\). Ignored wt provided. wt numeric vector inverse probability weights (IPW) balancing weights. provided, `ps` ignored. ate_flag integer (0 1) specifying target estimand. default 1, estimates Average Treatment Effect (ATE) weighting observations equally. Setting 0 estimates Average Treatment Effect Treated (ATT), treated units fully weighted control units downweighted based propensity scores. Ignored wt provided. See lbc_net information ATT, ATE, corresponding weighting schemes. ... Additional arguments passed specific method.","code":""},{"path":"/reference/gsd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Global Standardized Mean Difference (GSD) — gsd","text":"numeric vector containing GSD values covariate.","code":""},{"path":"/reference/gsd.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute Global Standardized Mean Difference (GSD) — gsd","text":"Definition GSD: GSD measures covariate balance across treatment groups: $$ GSD = \\frac{| \\mu_1 - \\mu_0 | }{ \\sqrt{ ( m_1 v_1 + m_0 v_0 )/(m_1 + m_0) } } \\times 100\\% $$ : - \\(\\mu_1\\) \\(\\mu_0\\) IPTW-weighted means treated control groups:   $$   \\mu_1 = \\frac{\\sum_{=1}^{N} T_i W_i X_i }{ \\sum_{=1}^{N} T_i W_i }, \\quad   \\mu_0 = \\frac{\\sum_{=1}^{N} (1-T_i) W_i X_i }{ \\sum_{=1}^{N} (1-T_i) W_i }.   $$ - \\(v_1\\) \\(v_0\\) corresponding weighted variances:   $$   v_1 = \\frac{\\sum_{=1}^{N} T_i W_i (X_i - \\mu_1)^2 }{ \\sum_{=1}^{N} T_i W_i - 1 }, \\quad   v_0 = \\frac{\\sum_{=1}^{N} (1-T_i) W_i (X_i - \\mu_0)^2 }{ \\sum_{=1}^{N} (1-T_i) W_i - 1 }.   $$ - \\(m_1\\) \\(m_0\\) effective sample sizes (ESS) treated control groups:   $$   m_1 = \\frac{ (\\sum_{=1}^{N} T_i W_i)^2 }{ \\sum_{=1}^{N} T_i W_i^2 }, \\quad   m_0 = \\frac{ (\\sum_{=1}^{N} (1-T_i) W_i)^2 }{ \\sum_{=1}^{N} (1-T_i) W_i^2 }.   $$ Automatic Extraction `lbc_net` Object `lbc_net` object provided.","code":""},{"path":"/reference/gsd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute Global Standardized Mean Difference (GSD) — gsd","text":"","code":"# Example with manually provided inputs set.seed(123) Z <- matrix(rnorm(200), nrow = 100, ncol = 2) Tr <- rbinom(100, 1, 0.5) ps <- runif(100, 0.1, 0.9)  # Simulated propensity scores  # Compute GSD using propensity scores gsd(Z = Z, Tr = Tr, ps = ps) #>         V1         V2  #> -14.193571   2.216594   # Compute GSD using weights wt <- 1 / (Tr * ps + (1 - Tr) * (1 - ps))  # Convert ps to weights gsd(Z = Z, Tr = Tr, wt = wt) #>         V1         V2  #> -14.193571   2.216594   if (FALSE) { # \\dontrun{ # Example with an lbc_net object model <- lbc_net(data = data, formula = Tr ~ X1 + X2 + X3 + X4) gsd(model) } # }"},{"path":"/reference/lbc_net-class.html","id":null,"dir":"Reference","previous_headings":"","what":"Class ","title":"Class ","text":"object class `lbc_net` represents fitted LBC-Net model, including estimated propensity scores, local balance metrics, model parameters.","code":""},{"path":"/reference/lbc_net-class.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Class ","text":"`lbc_net` class provides methods extracting fitted values, evaluating balance, summarizing model performance. available S3 methods objects class `lbc_net`:","code":""},{"path":"/reference/lbc_net-class.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Class ","text":"functions `gsd()` `lsd()` standard (non-S3) functions called directly: methods allow users efficiently analyze interpret results LBC-Net model causal inference.","code":"## S3 method for class 'lbc_net' est_effect(object, Y, ...)  ## S3 method for class 'lbc_net' getLBC(object, names, ...)  ## S3 method for class 'lbc_net' print(object, ...)  ## S3 method for class 'lbc_net' summary(object, ...) gsd(object, ...) lsd(object, ...)"},{"path":[]},{"path":"/reference/lbc_net.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate Propensity Scores Using LBC-Net — lbc_net","title":"Estimate Propensity Scores Using LBC-Net — lbc_net","text":"`lbc_net` estimates propensity scores using LBC-Net model, deep learning method designed enhance covariate balance. integrates Variational Autoencoder (VAE) customized neural network estimate treatment probabilities causal inference. outcome `Y` supplied, `lbc_net` also computes inverse probability weighted (IPW) estimates causal effect (ATE ATT) , enabled, corresponding influence-function–based standard errors confidence intervals.","code":""},{"path":"/reference/lbc_net.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate Propensity Scores Using LBC-Net — lbc_net","text":"","code":"lbc_net(   data = NULL,   formula = NULL,   Z = NULL,   Tr = NULL,   Y = NULL,   estimand = c(\"ATE\", \"ATT\", \"Y\"),   K = 99,   rho = 0.15,   na.action = na.fail,   gpu = 0,   show_progress = TRUE,   ...,   setup_lbcnet_args = list() )"},{"path":"/reference/lbc_net.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate Propensity Scores Using LBC-Net — lbc_net","text":"data optional data frame, list, environment (object coercible `.data.frame` data frame) containing variables specified `formula`. variable found `data`, taken `environment(formula)`, typically environment `lbc_net()` called. `formula` provided, `Z` (matrix covariates) `Tr` (numeric treatment assignment vector) must explicitly supplied. formula object class `\"formula\"` (one can coerced class), specifying symbolic description model form `Tr ~ X1 + X2 + ...`. `formula` provided, `Z` `Tr` extracted `data`. omitted, `Z` `Tr` must supplied explicitly. Z numeric matrix data frame covariates. Required `formula` provided. row represents observation, column represents covariate. `formula` used, `Z` extracted `data` automatically. Tr numeric vector representing treatment assignment (typically 0/1). Required `formula` provided. Must number rows `Z`. `formula` used, `Tr` extracted `data` automatically. Y Optional numeric vector observed outcomes. provided, `lbc_net` , addition estimating propensity scores, compute inverse probability weighted estimates causal estimand (e.g., ATE ATT) using fitted LBC-Net model. `Y` can continuous binary; IPW formula , interpretation differs. estimand Character string specifying target estimand outcome `Y` supplied. Available options : `\"ATE\"` Average Treatment Effect. frequency weight function     \\(\\omega^{*}(p_i) = 1\\) targets combined population. `\"ATT\"` Average Treatment Effect Treated. frequency weight     function \\(\\omega^{*}(p_i) = p_i\\) upweights units likely treated. `\"Y\"` Weighted mean outcome among treated group, using IPW weights     derived fitted propensity scores. `Y` `NULL`, `estimand` ignored `lbc_net` fits propensity model. See **Details** information ATT, ATE, corresponding weighting schemes. K integer specifying number grid center points used compute kernel weights local neighborhood. weights used assess balance calibration conditions. specified, `ck` automatically computed `k / (K + 1)`, `k = 1, ..., K`. default `99`, generating grid points `0.01` `0.99`. See **Details** information kernel weights. rho numeric value specifying span used determine adaptive bandwidth `h` `h` provided. span controls proportion data included local neighborhood, ensuring sufficient sample size accurate training. choice `rho` influences local balance assessment selected based data structure. cross-validation can used approximate optimal span, user discretion advised. default `0.15`. na.action function specify action taken NAs found. default action procedure fail. alternative `na.omit`, leads rejection cases missing values required variable. (NOTE: given, argument must named.) gpu integer specifying GPU device ID computation CUDA available. set `0`, function attempt use default GPU. CUDA unavailable, computations automatically fall back CPU. show_progress logical value indicating whether display progress bar training. `TRUE` (default), displays elapsed time, remaining time, loss values, training speed (iterations per second). helps monitor training progress efficiently. Set `FALSE` disable display. ... Additional parameters model tuning, including: `ck` numeric vector kernel center points. Values   strictly `0` `1`. `NULL`, `ck` automatically computed   using default `K`. provided, user-defined grid points   adhere constraint `0 < ck < 1`. `h` numeric vector bandwidth values kernel weighting.   default, adaptive bandwidth automatically computed via preliminary   probabilities estimated using logistic regression (`glm`), given `ck`   span parameter `rho`. `NULL`, `h` computed using   span_bw. `kernel` character string specifying kernel function used local   weighting. default `\"gaussian\"`. Available options include: `\"gaussian\"` (default): Ensures smooth weighting continuity. `\"uniform\"`: Assigns equal weight observations within fixed bandwidth. `\"epanechnikov\"`: Gives higher weight observations closer kernel center. See **Details** information kernel weighting role local   balance estimation. `seed` integer specifying random seed reproducibility training neural network.   seed applied PyTorch using `torch.manual_seed(seed)`, ensuring consistent results   across runs using stochastic optimization methods. `hidden_dim` integer specifying number hidden units LBC-Net model.   rule thumb set two three times number covariates,   significantly smaller sample size prevent overfitting.   Default `100`. `num_hidden_layers` integer specifying number hidden layers LBC-Net model.   Default `1`, results three-layer network overall (input layer, one hidden layer, output layer). `vae_epochs` integer specifying number training epochs Variational Autoencoder (VAE).   determines long VAE component model trained used LBC-Net.   Default `250`. `vae_lr` numeric value specifying learning rate training VAE using Adam optimizer.   Controls quickly model updates parameters training. Default `0.01`. `max_epochs` integer specifying maximum number training epochs LBC-Net.   Early stopping applied based `lsd_threshold` prevent unnecessary training.   Default `5000`. `lr` numeric value specifying initial learning rate LBC-Net training using Adam optimizer.   learning rate controls much model updates training step.   Default `0.05`. `weight_decay` numeric value specifying regularization parameter Adam optimizer LBC-Net.   Helps prevent overfitting penalizing large weights model.   Default `1e-5`. `balance_lambda` numeric value controlling relative contributions local balance loss (\\(Q_1\\))   calibration loss (\\(Q_2\\)) objective function, total loss defined   \\(Q = Q_1 + \\lambda Q_2\\). Default `1.0`. `epsilon` small numeric value controlling lower upper bounds   estimated propensity scores. default `0.001`, ensuring scores remain within   \\([\\epsilon, 1 - \\epsilon]\\) numerical stability, particularly cases   poor overlap. Setting `epsilon = 0` reverts standard logit link function.   See **Details** role model stabilization. `lsd_threshold` numeric value defining stopping criterion based Local Standardized mean Difference (LSD).   Training stops rolling average maximum local balance falls threshold.   default `lsd_threshold = 2` balances efficiency precision. cases poor overlap small   sample sizes, relaxed threshold (e.g., `5%` `10%`) may used allow flexibility training. `rolling_window` integer specifying number recent epochs used compute rolling average   maximum local balance. Default `5`. early stopping mechanism triggered rolling average   maximum LSD recent `rolling_window` epochs falls `lsd_threshold`. Specifically,   every 200-epoch step, maximum local balance calculated, rolling average last   `rolling_window` steps updated. Training halts rolling average drops `lsd_threshold`,   predefined maximum epochs reached, ensuring sufficient learning capacity. setup_lbcnet_args List. Optional arguments passed setup_lbcnet configuring Python environment. Python set , `setup_lbcnet()` automatically called using parameters. Default `list(envname = \"r-lbcnet\", create_if_missing = TRUE)`, meaning attempt use virtual environment `\"r-lbcnet\"` create missing.","code":""},{"path":"/reference/lbc_net.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate Propensity Scores Using LBC-Net — lbc_net","text":"object class `\"lbc_net\"`, containing: `fitted.values`: Estimated propensity scores. `weights`: Inverse probability weights (IPW). model components (e.g., `losses`, `parameters`, `Z`, `Tr`) accessible via `$` recommended getLBC function. direct access (e.g., `fit$fitted.values`) possible, using `getLBC(fit, \"fitted.values\")` recommended stability future-proofing.","code":""},{"path":"/reference/lbc_net.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimate Propensity Scores Using LBC-Net — lbc_net","text":"function optimizes objective function \\(Q(\\theta)\\) using feed-forward neural network batch normalization layer. Rectified Linear Unit (ReLU) activations used hidden layers, output layer employs modified sigmoid activation ensure propensity scores remain bounded \\(\\epsilon\\) \\(1-\\epsilon\\): $$ p(\\mathbf{Z}) = \\epsilon + (1 - 2\\epsilon) \\frac{\\exp(S(\\mathbf{Z}; \\theta))}{1 + \\exp(S(\\mathbf{Z}; \\theta))} $$ well-overlapping distributions, \\(\\epsilon = 0\\) (logit link function) effective, poor overlap, \\(\\epsilon = 0.001\\) stabilizes computation preventing extreme probabilities (0 1). default \\(\\epsilon = 0.001\\) works well cases. categorical covariates two levels included `formula` `Z`, users must manually convert dummy (one-hot encoded) variables fitting model. can done follows: Optimization Process: model trained using Adaptive Moment Estimation (ADAM) optimization. Given complexity objective function, pre-training phase using Variational Autoencoder (VAE) incorporated enhance feature representation. pre-training, encoder weights transferred initialize LBC-Net. initialization improves training stability propensity score estimation. Kernel Weighting & Local Inverse Probability Weights (IPW): weigh observations local neighborhoods, use kernel smoothing define local balance weights. default choice package Gaussian kernel due smoothness continuity, users may specify alternative kernels. general form kernel weighting function : $$\\omega(c_k, x) = h_k^{-1} K\\left( \\frac{c_k - x}{h_k} \\right)$$ \\(h_k\\) location-specific bandwidth, \\(K(x)\\) kernel function. default Gaussian kernel given : $$K(x) = (2\\pi)^{-1/2} \\exp(-x^2/2)$$ Alternative Kernel Choices: Users can modify kernel function different weighting schemes: Uniform Kernel:          $$K(x) = 0.5 \\times \\mathbf{1}(|x| \\leq 1)$$ Epanechnikov Kernel:          $$K(x) = 0.75 (1 - x^2) \\mathbf{1}(|x| \\leq 1)$$ Local Inverse Probability Weight (LIPW) local grid center \\(c_k\\) : $$ W_k(p_i) = \\frac{ \\omega(c_k, p_i)\\omega^*(p_i) }{ T_i p_i + (1 - T_i)(1 - p_i) }, \\quad = 1, 2, ..., N. $$ frequency weight function \\(\\omega^{*}(p_i)\\) determines target population: setting \\(\\omega^{*}(p_i) = 1\\) yields Average Treatment Effect (ATE), choosing \\(\\omega^{*}(p_i) = p_i\\) results Average Treatment Effect Treated (ATT). Training Considerations & Tuning: - Poor Overlap Situations: groups poor overlap   (see mirror_hist), achieving minimum local balance may difficult.   cases, relax `lsd_threshold` increase `max_epochs`. - Tuning Neural Network Parameters: local balance (`LSD`) loss   summary can guide tuning. However, default values   generally work well cases. - LSD metric used evaluate local balance guide hyperparameter tuning. - training, model tracks LSD values determine convergence. can retrieved using: getLBC(object, \"max_lsd\"):     Returns maximum LSD last epoch training; getLBC(object, \"mean_lsd\"):     Returns mean LSD. - final evaluation: lsd(object):          Computes final LSD values based fitted model; plot.lsd(object):          Generates visualizations LSD values across covariates; plot_calib(object):          Assesses local calibration estimated propensity scores. mirror_hist(object):          Mirror histogram propensity score distribution groups.","code":"data$cate <- factor(data$cate) dummy_vars <- model.matrix(~ cate - 1, data = data) data <- cbind(data, dummy_vars) data$cate <- NULL"},{"path":[]},{"path":"/reference/lbc_net.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate Propensity Scores Using LBC-Net — lbc_net","text":"","code":"if (FALSE) { # \\dontrun{ # Set seed for reproducibility set.seed(123456)  # Define sample size n <- 5000  # Generate true covariates from a multivariate normal distribution if (requireNamespace(\"MASS\", quietly = TRUE)) {   Z <- MASS::mvrnorm(n, mu = rep(0, 4), Sigma = diag(4)) }  # Generate propensity scores (true model) prop <- 1 / (1 + exp(Z[,1] - 0.5 * Z[,2] +                       0.25 * Z[,3] + 0.1 * Z[,4]))  # Assign treatment based on propensity scores Tr <- rbinom(n, 1, prop)  # Generate continuous outcome (correctly specified model) Y <- 210 + 27.4 * Z[,1] + 13.7 * Z[,2] +      13.7 * Z[,3] + 13.7 * Z[,4] + rnorm(n)  # Estimate propensity scores with a misspecified model X <- cbind(exp(Z[,1] / 2),            Z[,2] * (1 + exp(Z[,1]))^(-1) + 10,            ((Z[,1] * Z[,3]) / 25 + 0.6)^3,            (Z[,2] + Z[,4] + 20)^2)  # Combine data into a data frame data <- data.frame(Y, Tr, X) colnames(data) <- c(\"Y\", \"Tr\", \"X1\", \"X2\", \"X3\", \"X4\")  # --- Fit the LBC-Net Model (propensity only) ---  # Option 1: Using formula input (PS + diagnostics only) model_ps <- lbc_net(data = data, formula = Tr ~ X1 + X2 + X3 + X4)  # Option 2: Directly using Z and Tr model_ps2 <- lbc_net(Z = X, Tr = Tr)  # --- Fit the LBC-Net Model and estimate ATE in one step --- model_ate <- lbc_net(   data     = data,   formula  = Tr ~ X1 + X2 + X3 + X4,   Y        = data$Y,   estimand = \"ATE\" )  print(model_ate)          # basic print summary(model_ate)        # may show effect and PS summaries  # Extract effect and SE getLBC(model_ate, \"effect\") getLBC(model_ate, \"se\")  # --- Performance Evaluation ---  # Mirror histogram of propensity scores mirror_hist(model)  # Calibration plot plot_calib(model)  # Compute and plot the LSD metric lsd.fit <- lsd(model) plot(lsd.fit) } # }"},{"path":"/reference/lbc_net_surv.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate Survival Difference Using LBC-Net and IPW Nelson–Aalen — lbc_net_surv","title":"Estimate Survival Difference Using LBC-Net and IPW Nelson–Aalen — lbc_net_surv","text":"`lbc_net_surv()` extends lbc_net time--event outcomes. first estimates propensity scores via LBC-Net combines inverse probability weights (IPW) construct IPW-weighted Nelson–Aalen estimators marginal survival functions treatment control. primary estimand survival difference \\(S_1(t) - S_0(t)\\) one time points, survival estimators based IPW-weighted Nelson–Aalen approach Deng Wang (2025).","code":""},{"path":"/reference/lbc_net_surv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate Survival Difference Using LBC-Net and IPW Nelson–Aalen — lbc_net_surv","text":"","code":"lbc_net_surv(   data = NULL,   formula = NULL,   Z = NULL,   Tr = NULL,   time = NULL,   delta = NULL,   K = 99,   rho = 0.15,   na.action = na.fail,   gpu = 0,   show_progress = TRUE,   t_star = NULL,   t_grid = NULL,   ...,   setup_lbcnet_args = list() )"},{"path":"/reference/lbc_net_surv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate Survival Difference Using LBC-Net and IPW Nelson–Aalen — lbc_net_surv","text":"data optional data frame, list, environment (object coercible `.data.frame` data frame) containing variables specified `formula`. variable found `data`, taken `environment(formula)`, typically environment `lbc_net()` called. `formula` provided, `Z` (matrix covariates) `Tr` (numeric treatment assignment vector) must explicitly supplied. formula object class `\"formula\"` (one can coerced class), specifying symbolic description model form `Tr ~ X1 + X2 + ...`. `formula` provided, `Z` `Tr` extracted `data`. omitted, `Z` `Tr` must supplied explicitly. Z numeric matrix data frame covariates. Required `formula` provided. row represents observation, column represents covariate. `formula` used, `Z` extracted `data` automatically. Tr numeric vector representing treatment assignment (typically 0/1). Required `formula` provided. Must number rows `Z`. `formula` used, `Tr` extracted `data` automatically. time Event censoring time. can : numeric vector length equal sample size, character string naming column `data` contains     event/censoring times. delta Event indicator (1 = event, 0 = censored). can : numeric integer vector length equal sample size, character string naming column `data` contains     event indicator. K integer specifying number grid center points used compute kernel weights local neighborhood. weights used assess balance calibration conditions. specified, `ck` automatically computed `k / (K + 1)`, `k = 1, ..., K`. default `99`, generating grid points `0.01` `0.99`. See **Details** information kernel weights. rho numeric value specifying span used determine adaptive bandwidth `h` `h` provided. span controls proportion data included local neighborhood, ensuring sufficient sample size accurate training. choice `rho` influences local balance assessment selected based data structure. cross-validation can used approximate optimal span, user discretion advised. default `0.15`. na.action function specify action taken NAs found. default action procedure fail. alternative `na.omit`, leads rejection cases missing values required variable. (NOTE: given, argument must named.) gpu integer specifying GPU device ID computation CUDA available. set `0`, function attempt use default GPU. CUDA unavailable, computations automatically fall back CPU. show_progress logical value indicating whether display progress bar training. `TRUE` (default), displays elapsed time, remaining time, loss values, training speed (iterations per second). helps monitor training progress efficiently. Set `FALSE` disable display. t_star Optional numeric value giving single time point \\(t^*\\) highlight survival difference \\(S_1(t^*) - S_0(t^*)\\) output. `t_star = NULL` (default), function sets \\(t^*\\) median survival time control group based Kaplan–Meier estimator; median undefined (e.g., events control), pooled-sample median used instead. t_grid Optional numeric vector time points evaluate survival curves survival difference. `t_grid` `NULL` `t_star` specified imputed (default), function uses single-point grid equal `t_star`. `t_grid` non-`NULL`, overrides `t_star` evaluation purposes `t_star` still recorded output object. ... Additional parameters model tuning, including: `ck` numeric vector kernel center points. Values   strictly `0` `1`. `NULL`, `ck` automatically computed   using default `K`. provided, user-defined grid points   adhere constraint `0 < ck < 1`. `h` numeric vector bandwidth values kernel weighting.   default, adaptive bandwidth automatically computed via preliminary   probabilities estimated using logistic regression (`glm`), given `ck`   span parameter `rho`. `NULL`, `h` computed using   span_bw. `kernel` character string specifying kernel function used local   weighting. default `\"gaussian\"`. Available options include: `\"gaussian\"` (default): Ensures smooth weighting continuity. `\"uniform\"`: Assigns equal weight observations within fixed bandwidth. `\"epanechnikov\"`: Gives higher weight observations closer kernel center. See **Details** information kernel weighting role local   balance estimation. `seed` integer specifying random seed reproducibility training neural network.   seed applied PyTorch using `torch.manual_seed(seed)`, ensuring consistent results   across runs using stochastic optimization methods. `hidden_dim` integer specifying number hidden units LBC-Net model.   rule thumb set two three times number covariates,   significantly smaller sample size prevent overfitting.   Default `100`. `num_hidden_layers` integer specifying number hidden layers LBC-Net model.   Default `1`, results three-layer network overall (input layer, one hidden layer, output layer). `vae_epochs` integer specifying number training epochs Variational Autoencoder (VAE).   determines long VAE component model trained used LBC-Net.   Default `250`. `vae_lr` numeric value specifying learning rate training VAE using Adam optimizer.   Controls quickly model updates parameters training. Default `0.01`. `max_epochs` integer specifying maximum number training epochs LBC-Net.   Early stopping applied based `lsd_threshold` prevent unnecessary training.   Default `5000`. `lr` numeric value specifying initial learning rate LBC-Net training using Adam optimizer.   learning rate controls much model updates training step.   Default `0.05`. `weight_decay` numeric value specifying regularization parameter Adam optimizer LBC-Net.   Helps prevent overfitting penalizing large weights model.   Default `1e-5`. `balance_lambda` numeric value controlling relative contributions local balance loss (\\(Q_1\\))   calibration loss (\\(Q_2\\)) objective function, total loss defined   \\(Q = Q_1 + \\lambda Q_2\\). Default `1.0`. `epsilon` small numeric value controlling lower upper bounds   estimated propensity scores. default `0.001`, ensuring scores remain within   \\([\\epsilon, 1 - \\epsilon]\\) numerical stability, particularly cases   poor overlap. Setting `epsilon = 0` reverts standard logit link function.   See **Details** role model stabilization. `lsd_threshold` numeric value defining stopping criterion based Local Standardized mean Difference (LSD).   Training stops rolling average maximum local balance falls threshold.   default `lsd_threshold = 2` balances efficiency precision. cases poor overlap small   sample sizes, relaxed threshold (e.g., `5%` `10%`) may used allow flexibility training. `rolling_window` integer specifying number recent epochs used compute rolling average   maximum local balance. Default `5`. early stopping mechanism triggered rolling average   maximum LSD recent `rolling_window` epochs falls `lsd_threshold`. Specifically,   every 200-epoch step, maximum local balance calculated, rolling average last   `rolling_window` steps updated. Training halts rolling average drops `lsd_threshold`,   predefined maximum epochs reached, ensuring sufficient learning capacity. setup_lbcnet_args List. Optional arguments passed setup_lbcnet configuring Python environment. Python set , `setup_lbcnet()` automatically called using parameters. Default `list(envname = \"r-lbcnet\", create_if_missing = TRUE)`, meaning attempt use virtual environment `\"r-lbcnet\"` create missing.","code":""},{"path":"/reference/lbc_net_surv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate Survival Difference Using LBC-Net and IPW Nelson–Aalen — lbc_net_surv","text":"object class \"lbc_net_surv\" (\"lbc_net\"), containing: fitted.values: Estimated propensity scores \\(\\hat e(X)\\). weights: IPW weights survival: list components: times: Time grid survival functions evaluated. S1: Estimated survival function treatment. S0: Estimated survival function control. diff: Estimated survival difference S1 - S0 time. se_diff: Standard error survival difference. ci_lower: Lower bound 95% Wald CI         survival difference. ci_upper: Upper bound 95% Wald CI         survival difference. t_star: highlighted time point (median control survival         default, user-supplied).","code":""},{"path":"/reference/lbc_net_surv.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimate Survival Difference Using LBC-Net and IPW Nelson–Aalen — lbc_net_surv","text":"Let \\(T\\) event censoring time, \\(\\Delta\\) event indicator (1 = event, 0 = censored), \\(\\\\{0,1\\}\\) treatment. LBC-Net first estimates propensity score \\(e(X) = P(= 1 \\mid X)\\) using deep learning framework lbc_net, local balance calibration constraints. resulting propensity scores \\(\\hat e(X)\\) used form Inverse Probability Weights $$   W_i =   \\frac{1}{A_i \\hat e(X_i) + (1 - A_i)\\{1 - \\hat e(X_i)\\}}, $$ corresponding frequency weight function \\(\\omega^{*}(p) = 1\\) (additional tilting). Using weights, Deng Wang's (2025) IPW–Nelson–Aalen estimator applied separately treated control groups obtain cumulative hazards \\(\\hat\\Lambda_1(t)\\), \\(\\hat\\Lambda_0(t)\\), survival functions $$   \\hat S_a(t) = \\exp\\{-\\hat\\Lambda_a(t)\\}, \\quad \\\\{0,1\\}. $$ function returns estimated survival difference $$   \\hat\\Delta(t) = \\hat S_1(t) - \\hat S_0(t) $$ evaluated user-specified grid time points `t_grid`. user provide grid specific `t_star`, default evaluation time set median survival time control arm, estimated standard Kaplan–Meier curve based observed data. stage, `lbc_net_surv()` provides point estimates \\(\\hat S_1(t)\\), \\(\\hat S_0(t)\\), difference \\(\\hat\\Delta(t)\\) along variance estimation influence-function-based standard errors survival difference evaluation time.","code":""},{"path":"/reference/lbc_net_surv.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Estimate Survival Difference Using LBC-Net and IPW Nelson–Aalen — lbc_net_surv","text":"Compared lbc_net, function: uses time delta instead outcome Y, ignores outcome-related arguments Y,         outcome_type, estimand flags (ATE/ATT/Y).","code":""},{"path":[]},{"path":"/reference/lbc_net_surv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate Survival Difference Using LBC-Net and IPW Nelson–Aalen — lbc_net_surv","text":"","code":"if (FALSE) { # \\dontrun{   set.seed(123)   n  <- 1000   X1 <- rnorm(n)   X2 <- rnorm(n)   Tr <- rbinom(n, 1, plogis(0.5 * X1 - 0.3 * X2))    lambda0 <- 0.02   hr      <- 0.7   rate    <- lambda0 * ifelse(Tr == 1, hr, 1)   T_true  <- rexp(n, rate = rate)   C       <- rexp(n, rate = 0.01)    time  <- pmin(T_true, C)   delta <- as.integer(T_true <= C)    dat <- data.frame(Tr = Tr, X1 = X1, X2 = X2,                     time = time, delta = delta)    fit_surv <- lbc_net_surv(     data    = dat,     formula = Tr ~ X1 + X2,     time    = \"time\",     delta   = \"delta\"   )    # Estimated survival difference and SE at evaluation times   head(cbind(     time = fit_surv$survival$times,     diff = fit_surv$survival$diff,     se   = fit_surv$survival$se_diff   )) } # }"},{"path":"/reference/lsd.html","id":null,"dir":"Reference","previous_headings":"","what":"Local Standardized Mean Difference (LSD) Calculation — lsd","title":"Local Standardized Mean Difference (LSD) Calculation — lsd","text":"Computes Local Standardized Mean Difference (LSD) assessing local balance causal inference. LSD measures standardized mean difference covariates pre-specified grid points `ck` using kernel-based local inverse probability weighting propensity scores.","code":""},{"path":"/reference/lsd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Local Standardized Mean Difference (LSD) Calculation — lsd","text":"","code":"lsd(   object = NULL,   Z = NULL,   Tr = NULL,   ps = NULL,   ck = NULL,   h = NULL,   K = 99,   rho = 0.15,   kernel = \"gaussian\",   ate_flag = 1,   ... )"},{"path":"/reference/lsd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Local Standardized Mean Difference (LSD) Calculation — lsd","text":"object optional object class `lbc_net`. provided, extracts `Z`, `Tr`, `ps`, `ck`, `h`, `kernel`. Z matrix data frame covariates. Required `object` provided. Tr binary vector indicating treatment assignment (1 treatment, 0 control). Required `object` provided. ps vector propensity scores. Required `object` provided. ck numeric vector pre-specified grid points local balance assessment. NULL, automatically calculated. h numeric vector bandwidths. NULL, automatically calculated. K number grid points use `ck` provided. Default 99. rho scaling parameter used bandwidth calculation. Default 0.15. kernel kernel function used. Options \"gaussian\", \"uniform\", \"epanechnikov\". Default \"gaussian\". ate_flag integer (0 1) specifying target estimand. default 1, estimates Average Treatment Effect (ATE) weighting observations equally. Setting 0 estimates Average Treatment Effect Treated (ATT), treated units fully weighted control units downweighted based propensity scores. See Details lbc_net. ... Additional arguments passed specific method.","code":""},{"path":"/reference/lsd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Local Standardized Mean Difference (LSD) Calculation — lsd","text":"object `lsd` containing LSD values (%) covariate, includes: `LSD`: matrix LSD values covariate `ck`. `LSD_mean`: mean absolute LSD value across covariates. `LSD_max`: maximum absolute LSD value. model components (e.g., `Z`, `Tr`) accessible via `$` recommended getLBC function. direct access (e.g., `fit$fitted.values`) possible, using `getLBC(fit, \"LSD\")` recommended stability future-proofing.","code":""},{"path":"/reference/lsd.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Local Standardized Mean Difference (LSD) Calculation — lsd","text":"See lbc_net details local kernel weights arguments `ck`, `h`, `K`, `rho`, `kernel`. formula LSD follows structure Global Standardized Mean Difference (GSD) (gsd), weights `W_i` replaced `W'_i`, Local Inverse Probability Weight (LIPW). LSD expressed percentage absolute value. Like GSD, LSD can used assessing balance covariates, LSD specific propensity score-based methods.","code":""},{"path":"/reference/lsd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Local Standardized Mean Difference (LSD) Calculation — lsd","text":"","code":"# Example with manually provided inputs set.seed(123) Z <- matrix(rnorm(200), nrow = 100, ncol = 2) Tr <- rbinom(100, 1, 0.5) ps <- runif(100, 0.1, 0.9)  # Simulated propensity scores  # Compute LSD using manually provided inputs lsd_result <- lsd(Z = Z, Tr = Tr, ps = ps, K = 99) #> Calculating propensity scores for ck/h calculation... print(lsd_result) #> Sample Size: 100  | Treated: 46  | Control: 54  #> Estimand: ATE (Average Treatment Effect)  #>  #> --- Local Balance (LSD) % --- #> Max LSD: 262.5544  #> Mean LSD: 35.2833  #>  #> Kernel: \"gaussian\"  #>  #> Use summary(object) for a full model summary. summary(lsd_result) #> Call: #>  function (x, ...)  UseMethod(\"formula\")  #> Sample Size: 100  | Number of Covariates: 2  #> Treated: 46  | Control: 54  #> Estimand: ATE (Average Treatment Effect)  #>  #> --- Local Balance (LSD) % --- #> Max LSD:   262.5544 #> Mean LSD:  35.2833 #>  #> Covariates   LSD %  #> -------------  #> Z1   46.9875  #> Z2   23.5791  #>   # Compute and visualize LSD results plot(lsd_result)   if (FALSE) { # \\dontrun{ # Fit LBC-Net model model <- lbc_net(data = data, formula = Tr ~ X1 + X2 + X3 + X4)  # Compute LSD from the fitted model for ATE. lsd_fit <- lsd(model) print(lsd_fit) summary(lsd_result)  # Visualize LSD results plot(lsd_fit) } # }"},{"path":"/reference/mirror_hist.html","id":null,"dir":"Reference","previous_headings":"","what":"Mirror Histogram of Propensity Scores — mirror_hist","title":"Mirror Histogram of Propensity Scores — mirror_hist","text":"Creates mirror histogram compare distribution propensity scores treated control groups introduced Li Greene (2013).","code":""},{"path":"/reference/mirror_hist.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mirror Histogram of Propensity Scores — mirror_hist","text":"","code":"mirror_hist(   object = NULL,   ps = NULL,   Tr = NULL,   bins = 70,   size = 0.5,   theme.size = 15,   grid = TRUE,   ... )"},{"path":"/reference/mirror_hist.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mirror Histogram of Propensity Scores — mirror_hist","text":"object optional object class `lbc_net`. provided, extracts `ps` (fitted propensity scores) `Tr` (treatment assignment). ps numeric vector propensity scores. Required `object` provided. Tr binary numeric vector indicating treatment assignment (1 treatment, 0 control). Required `object` provided. bins Integer specifying number bins histogram. Default 70. size Numeric specifying line size histogram bars. Default 0.5. theme.size Numeric specifying base font size theme. Default `15`. grid Logical indicating whether include gridlines plot background. Default `TRUE`. ... Additional arguments passed `ggplot2` layers customization.","code":""},{"path":"/reference/mirror_hist.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mirror Histogram of Propensity Scores — mirror_hist","text":"`ggplot2` object customization direct display.","code":""},{"path":"/reference/mirror_hist.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Mirror Histogram of Propensity Scores — mirror_hist","text":"function creates mirror histogram control group (Z=0) displayed x-axis treatment group (Z=1) displayed x-axis, making easier compare distribution propensity scores across groups.","code":""},{"path":"/reference/mirror_hist.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mirror Histogram of Propensity Scores — mirror_hist","text":"","code":"# Example with manually provided propensity scores and treatment indicators set.seed(123) ps <- runif(10000)  # Simulated propensity scores Tr <- sample(0:1, 10000, replace = TRUE)  # Random treatment assignment mirror_hist(ps = ps, Tr = Tr, bins = 50, size = 0.8)   if (FALSE) { # \\dontrun{ # Example with an `lbc_net` object model <- lbc_net(data = data, formula = Tr ~ X1 + X2 + X3 + X4) mirror_hist(model) } # }"},{"path":"/reference/plot.lsd.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Local Standardized Mean Difference (LSD) Results — plot.lsd","title":"Plot Local Standardized Mean Difference (LSD) Results — plot.lsd","text":"Creates plots Local Standardized Mean Difference (LSD) `lsd` object. function provides visualization options: Average LSD covariates (default), option include box plots. LSD specific covariate name column index.","code":""},{"path":"/reference/plot.lsd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Local Standardized Mean Difference (LSD) Results — plot.lsd","text":"","code":"# S3 method for class 'lsd' plot(x, y = NULL, cov = \"ALL\", ...)"},{"path":"/reference/plot.lsd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Local Standardized Mean Difference (LSD) Results — plot.lsd","text":"x object class `lsd` created using lsd. y Unused, included compatibility plot generic. cov Character string numeric index specifying covariate plot. Use `\"\"` average covariates (default), specify covariate name column index. ... Additional parameters customizing plot, including limited : `box.loc` numeric vector specifying locations box plots `cov = \"\"`.     Must subset grid points `ck`. Default `seq(0.1, 0.9, = 0.2)`. Set `NULL` disable box plots. `point.color` Character string specifying color points plot. Default `\"#9467bd\"`. `point.size` Numeric specifying size points plot. Default `0.8`. `line.size` Numeric specifying size lines plot. Default `0.5`. `line.color` Character string specifying color lines plot. Default `\"black\"`. `theme.size` Numeric specifying base font size theme. Default `15`. `boxplot.width` Numeric specifying width box plots. Default `0.02`. `outlier.shape` Numeric specifying shape outliers box plots. Default `4`. `outlier.size` Numeric specifying size outliers box plots. Default `1`.","code":""},{"path":"/reference/plot.lsd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Local Standardized Mean Difference (LSD) Results — plot.lsd","text":"`ggplot2` object customization direct display.","code":""},{"path":"/reference/plot.lsd.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot Local Standardized Mean Difference (LSD) Results — plot.lsd","text":"function provides flexible visualization LSD results evaluate local balance estimated propensity scores: `cov = \"\"`, plot shows average LSD covariates. `box.loc` specified, box plots added show variability. specific covariate selected using `cov` (either name column index), plot shows LSD covariate. Box plots applicable `cov = \"\"` `box.loc` `NULL`.","code":""},{"path":[]},{"path":"/reference/plot.lsd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Local Standardized Mean Difference (LSD) Results — plot.lsd","text":"","code":"if (FALSE) { # \\dontrun{ # Basic plot using an lsd object plot(lsd_fit)  # Plot average LSD across all covariates plot(lsd_result, cov = \"ALL\")  # Plot LSD for a specific covariate plot(lsd_result, cov = 1) plot(lsd_result, cov = \"Cov1\")  # Plot LSD for all covariates with box plots plot(lsd_fit, cov = \"ALL\", box.loc = seq(0.1, 0.9, by = 0.2))  # Customize the plot appearance plot(lsd_fit, cov = \"ALL\", point.color = \"red\", point.size = 1, line.size = 1) } # }"},{"path":"/reference/plot_calib.html","id":null,"dir":"Reference","previous_headings":"","what":"Calibration Plot for Propensity Scores — plot_calib","title":"Calibration Plot for Propensity Scores — plot_calib","text":"Creates calibration plot assess local calibration estimated propensity scores.","code":""},{"path":"/reference/plot_calib.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calibration Plot for Propensity Scores — plot_calib","text":"","code":"plot_calib(   object = NULL,   ps = NULL,   Tr = NULL,   breaks = 10,   theme.size = 15,   ref.color = \"red\",   ... )"},{"path":"/reference/plot_calib.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calibration Plot for Propensity Scores — plot_calib","text":"object optional object class `lbc_net`. ps numeric vector propensity scores. Required `object` provided. Tr binary numeric vector indicating treatment assignment (1 treatment, 0 control). Required `object` provided. breaks Integer specifying number bins divide propensity scores . Default 10. theme.size Numeric specifying base font size theme. Default `15`. ref.color Character specifying color reference line. Default \"red\". ... Additional arguments passed `ggplot2` layers customization.","code":""},{"path":"/reference/plot_calib.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calibration Plot for Propensity Scores — plot_calib","text":"`ggplot2` object customization direct display.","code":""},{"path":"/reference/plot_calib.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calibration Plot for Propensity Scores — plot_calib","text":"plot assesses local calibration model-based propensity score estimation methods. estimated propensity scores divided `breaks` equal-length intervals, average propensity scores treatment proportions calculated subgroup plotted. dashed red line represents 45-degree reference line, indicating perfect calibration. well-calibrated model align closely line, ensuring estimated propensity scores match observed treatment proportions within bin. Deviations suggest poor calibration.","code":""},{"path":"/reference/plot_calib.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calibration Plot for Propensity Scores — plot_calib","text":"","code":"# Example with manually provided propensity scores and treatment indicators set.seed(123) ps <- runif(100)  # Simulated propensity scores Tr <- sample(0:1, 100, replace = TRUE)  # Random treatment assignment plot_calib(ps = ps, Tr = Tr, breaks = 10)   if (FALSE) { # \\dontrun{ # Example with an `lbc_net` object model <- lbc_net(data = data, formula = Tr ~ X1 + X2 + X3 + X4) plot_calib(model) } # }"},{"path":"/reference/plot_cov_bal.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Covariate Distribution Between Groups — plot_cov_bal","title":"Plot Covariate Distribution Between Groups — plot_cov_bal","text":"Plots distribution specified covariate treated control groups. Allows visualization weighted unweighted distributions using histogram density plots.","code":""},{"path":"/reference/plot_cov_bal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Covariate Distribution Between Groups — plot_cov_bal","text":"","code":"plot_cov_bal(   object = NULL,   Z = NULL,   Tr = NULL,   wt = NULL,   use_weights = TRUE,   cov = NULL,   plot_type = c(\"density\", \"hist\"),   color_treated = \"red\",   color_control = \"blue\",   bins = 30,   alpha = 0.4,   theme.size = 15,   suppress = TRUE,   ... )"},{"path":"/reference/plot_cov_bal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Covariate Distribution Between Groups — plot_cov_bal","text":"object Optional. object class `lbc_net`. provided, extracts `Z`, `Tr`, weights. Z data frame matrix covariates. Required `object` provided. Tr binary numeric vector treatment assignment (1 = treated, 0 = control). Required `object` provided. wt numeric vector weights. NULL `object` provided, weights extracted `object`. Defaults `rep(1, length(Tr))` provided. use_weights Logical. `TRUE` (default), applies weights distributions. `FALSE`, shows unweighted covariate distribution, even `lbc_net` object provided. cov character string specifying covariate name plot. Defaults first column `Z`. plot_type Character string: either `\"hist\"` (histogram) `\"density\"` (default `\"density\"`). color_treated Color treated group. Default `\"red\"`. color_control Color control group. Default `\"blue\"`. bins Number bins histogram (`plot_type = \"hist\"`). Default `30`. alpha Transparency level fill. Default `0.4`. theme.size Base font size plot theme. Default `15`. suppress Logical. `TRUE` (default), suppresses warnings generated plot rendering (e.g., bandwidth selection warnings `density()`). `FALSE`, warnings displayed usual. ... Additional arguments passed `ggplot2` geoms.","code":""},{"path":"/reference/plot_cov_bal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Covariate Distribution Between Groups — plot_cov_bal","text":"`ggplot2` object showing covariate distribution.","code":""},{"path":"/reference/plot_cov_bal.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Covariate Distribution Between Groups — plot_cov_bal","text":"","code":"if (FALSE) { # \\dontrun{ # Using an lbc_net object plot_cov_bal(model, cov = \"X1\")  # Manual input plot_cov_bal(Z = Z, Tr = Tr, wt = weights, cov = \"X1\") } # }"},{"path":"/reference/print.lbc_net.html","id":null,"dir":"Reference","previous_headings":"","what":"Print Basic Information of an lbc_net Object — print.lbc_net","title":"Print Basic Information of an lbc_net Object — print.lbc_net","text":"Provides concise summary lbc_net object, including sample size, training loss, local balance (LSD) training process, key model hyperparameters.","code":""},{"path":"/reference/print.lbc_net.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print Basic Information of an lbc_net Object — print.lbc_net","text":"","code":"# S3 method for class 'lbc_net' print(x, ...)"},{"path":"/reference/print.lbc_net.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print Basic Information of an lbc_net Object — print.lbc_net","text":"x object class \"lbc_net\", generated lbc_net(). ... Additional arguments (ignored).","code":""},{"path":"/reference/print.lbc_net.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print Basic Information of an lbc_net Object — print.lbc_net","text":"Prints key training details model parameters.","code":""},{"path":[]},{"path":"/reference/print.lbc_net.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print Basic Information of an lbc_net Object — print.lbc_net","text":"","code":"if (FALSE) { # \\dontrun{ model <- lbc_net(data = data, formula = Tr ~ X1 + X2 + X3 + X4) print(model)  # Displays a concise overview } # }"},{"path":"/reference/print.lbc_net_surv.html","id":null,"dir":"Reference","previous_headings":"","what":"Print Basic Information of an lbc_net_surv Object — print.lbc_net_surv","title":"Print Basic Information of an lbc_net_surv Object — print.lbc_net_surv","text":"Provides concise summary \"lbc_net_surv\" object, including sample size, training loss, local balance (LSD) training, key model hyperparameters, estimated survival difference highlighted time point.","code":""},{"path":"/reference/print.lbc_net_surv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print Basic Information of an lbc_net_surv Object — print.lbc_net_surv","text":"","code":"# S3 method for class 'lbc_net_surv' print(x, ...)"},{"path":"/reference/print.lbc_net_surv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print Basic Information of an lbc_net_surv Object — print.lbc_net_surv","text":"x object class \"lbc_net_surv\", generated lbc_net_surv(). ... Additional arguments (ignored).","code":""},{"path":"/reference/print.lbc_net_surv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print Basic Information of an lbc_net_surv Object — print.lbc_net_surv","text":"Prints key training details, model parameters, brief summary survival difference. Invisibly returns x.","code":""},{"path":[]},{"path":"/reference/print.lbc_net_surv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print Basic Information of an lbc_net_surv Object — print.lbc_net_surv","text":"","code":"if (FALSE) { # \\dontrun{ fit_surv <- lbc_net_surv(   data    = dat,   formula = Tr ~ X1 + X2,   time    = \"time\",   delta   = \"delta\" ) print(fit_surv)  # Displays a concise survival-focused overview } # }"},{"path":"/reference/print.lsd.html","id":null,"dir":"Reference","previous_headings":"","what":"Print Basic Information of an lsd Object — print.lsd","title":"Print Basic Information of an lsd Object — print.lsd","text":"Provides concise summary lsd object local balance (LSD).","code":""},{"path":"/reference/print.lsd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print Basic Information of an lsd Object — print.lsd","text":"","code":"# S3 method for class 'lsd' print(x, ...)"},{"path":"/reference/print.lsd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print Basic Information of an lsd Object — print.lsd","text":"x object class \"lsd\", generated lsd(). ... Additional arguments (ignored).","code":""},{"path":"/reference/print.lsd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print Basic Information of an lsd Object — print.lsd","text":"Prints key training details model parameters.","code":""},{"path":[]},{"path":"/reference/print.lsd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print Basic Information of an lsd Object — print.lsd","text":"","code":"if (FALSE) { # \\dontrun{ model <- lbc_net(data = data, formula = Tr ~ X1 + X2 + X3 + X4) lsd_fit <- lsd(model) print(fit)  # Displays a concise overview } # }"},{"path":"/reference/setup_lbcnet.html","id":null,"dir":"Reference","previous_headings":"","what":"Setup Python Environment for LBCNet — setup_lbcnet","title":"Setup Python Environment for LBCNet — setup_lbcnet","text":"function configures Python environment LBCNet, ensuring correct Python version dependencies loaded. prioritizes virtual environments (`venv`) Conda unless explicitly requested. Additionally, users can explicitly choose use system Python.","code":""},{"path":"/reference/setup_lbcnet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Setup Python Environment for LBCNet — setup_lbcnet","text":"","code":"setup_lbcnet(   use_conda = FALSE,   envname = \"r-lbcnet\",   use_system_python = FALSE,   create_if_missing = FALSE,   system_python_path = NULL )"},{"path":"/reference/setup_lbcnet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Setup Python Environment for LBCNet — setup_lbcnet","text":"use_conda Logical. `TRUE`, attempts use Conda (`r-lbcnet`) instead virtualenv. Default `FALSE`, meaning virtualenv/system Python preferred. envname character string specifying name virtual environment Conda environment use. Default `\"r-lbcnet\"`. One can use `virtualenv_list()` `conda_list()` check available Python environments system. use_system_python Logical. `TRUE`, function force use system Python (`Sys.(\"python\")`) instead virtual environment Conda. Default `FALSE`. `use_system_python = TRUE` `use_conda = TRUE`, function prioritize system Python. create_if_missing Logical. `TRUE`, function creates specified virtual environment (`envname`) exist. Default `FALSE`, meaning warn `envname` missing list available environments. applies `use_conda = FALSE`, Conda environments must created manually. system_python_path character string specifying full path system Python executable. provided `use_system_python = TRUE`, overrides `Sys.(\"python\")`. Default `NULL`.","code":""},{"path":"/reference/setup_lbcnet.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Setup Python Environment for LBCNet — setup_lbcnet","text":"function configures Python environment return value.","code":""},{"path":"/reference/setup_lbcnet.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Setup Python Environment for LBCNet — setup_lbcnet","text":"function automatically detects best available Python environment. user specifies `envname`, tries activate environment. `use_system_python = TRUE` `use_conda = TRUE`, function prioritize system Python. ensures required Python packages (`torch`, `numpy`, `pandas`, `tqdm`) available using `py_require()`. recommended set `reticulate` package properly running `setup_lbcnet()`. encountering errors like `\"Python virtualenv\"`, advised delete recreate virtual environment. multiple Python versions exist system, ensure packages installed correct Python environment. Use `reticulate::py_config()` verify active Python environment running function.","code":""},{"path":"/reference/setup_lbcnet.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Setup Python Environment for LBCNet — setup_lbcnet","text":"","code":"if (FALSE) { # \\dontrun{ setup_lbcnet()  # Automatically configures the best available Python environment setup_lbcnet(envname = \"r-lbcnet\")  # Uses a specific virtual environment (warns if missing) setup_lbcnet(envname = \"r-lbcnet\", create_if_missing = TRUE)  # Creates \"r-lbcnet\" if missing setup_lbcnet(use_conda = TRUE)  # Forces Conda if available setup_lbcnet(use_system_python = TRUE)  # Forces to use system Python setup_lbcnet(use_system_python = TRUE, use_conda = TRUE)  # Prioritizes system Python over Conda } # }"},{"path":"/reference/span_bw.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Adaptive Bandwidth for Kernel Smoothing — span_bw","title":"Compute Adaptive Bandwidth for Kernel Smoothing — span_bw","text":"function calculates adaptive bandwidth values (`h`) kernel smoothing based given span (`rho`) estimated propensity scores (`p`). used lbc_net can also applied independently bandwidth selection kernel-based methods.","code":""},{"path":"/reference/span_bw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Adaptive Bandwidth for Kernel Smoothing — span_bw","text":"","code":"span_bw(rho, ck, p)"},{"path":"/reference/span_bw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Adaptive Bandwidth for Kernel Smoothing — span_bw","text":"rho Numeric. span (proportion data points) used determine adaptive bandwidth. Ensures sufficient local sample size accurate balance estimation. ck Numeric vector. Pre-specified kernel center points, strictly 0 1. p Numeric vector. Estimated propensity scores, values strictly 0 1. Typically generated logistic regression can user-supplied.","code":""},{"path":"/reference/span_bw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Adaptive Bandwidth for Kernel Smoothing — span_bw","text":"numeric vector bandwidth values (`h`), corresponding `ck`.","code":""},{"path":"/reference/span_bw.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute Adaptive Bandwidth for Kernel Smoothing — span_bw","text":"adaptive bandwidths (`h`) ensure local region contains approximately rho * N observations, N total number observations. helps maintain stable kernel-based local balance estimation.","code":""},{"path":"/reference/span_bw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute Adaptive Bandwidth for Kernel Smoothing — span_bw","text":"","code":"# Simulated dataset set.seed(123) N <- 500 Z <- as.data.frame(matrix(rnorm(N * 5), ncol = 5)) colnames(Z) <- paste0(\"X\", 1:5) T <- rbinom(N, 1, 0.5)  # Binary treatment assignment  # Logistic regression for propensity score estimation log.fit <- glm(T ~ ., data = Z, family = \"binomial\") p <- log.fit$fitted.values  # Extract estimated propensity scores  # Compute bandwidths ck <- seq(0.01, 0.99, 0.01)  # Kernel center points rho <- 0.15  # Span h <- span_bw(rho, ck, p) print(h) #>  [1] 0.444590162 0.434590162 0.424590162 0.414590162 0.404590162 0.394590162 #>  [7] 0.384590162 0.374590162 0.364590162 0.354590162 0.344590162 0.334590162 #> [13] 0.324590162 0.314590162 0.304590162 0.294590162 0.284590162 0.274590162 #> [19] 0.264590162 0.254590162 0.244590162 0.234590162 0.224590162 0.214590162 #> [25] 0.204590162 0.194590162 0.184590162 0.174590162 0.164590162 0.154590162 #> [31] 0.144590162 0.134590162 0.124590162 0.114590162 0.104590162 0.094590162 #> [37] 0.084590162 0.074590162 0.064590162 0.054590162 0.044590162 0.034836062 #> [43] 0.026058180 0.018778042 0.013555681 0.011022614 0.008362981 0.006701713 #> [49] 0.006711111 0.007392425 0.008403778 0.008432826 0.010520541 0.013910124 #> [55] 0.019944141 0.028128455 0.036604152 0.046604152 0.056604152 0.066604152 #> [61] 0.076604152 0.086604152 0.096604152 0.106604152 0.116604152 0.126604152 #> [67] 0.136604152 0.146604152 0.156604152 0.166604152 0.176604152 0.186604152 #> [73] 0.196604152 0.206604152 0.216604152 0.226604152 0.236604152 0.246604152 #> [79] 0.256604152 0.266604152 0.276604152 0.286604152 0.296604152 0.306604152 #> [85] 0.316604152 0.326604152 0.336604152 0.346604152 0.356604152 0.366604152 #> [91] 0.376604152 0.386604152 0.396604152 0.406604152 0.416604152 0.426604152 #> [97] 0.436604152 0.446604152 0.456604152"},{"path":"/reference/summary.lbc_net.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary of an lbc_net Object — summary.lbc_net","title":"Summary of an lbc_net Object — summary.lbc_net","text":"Provides structured summary `lbc_net` object, including loss values, balance assessments, (available) treatment effect estimate standard error confidence interval.","code":""},{"path":"/reference/summary.lbc_net.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary of an lbc_net Object — summary.lbc_net","text":"","code":"# S3 method for class 'lbc_net' summary(object, Y = NULL, type = \"ATE\", ...)"},{"path":"/reference/summary.lbc_net.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary of an lbc_net Object — summary.lbc_net","text":"object object class `\"lbc_net\"`, generated `lbc_net()`. Y (Optional) numeric vector observed outcomes. model originally fitted outcome `Y` inside lbc_net already contains stored treatment effect (variance), argument ignored stored results reported. treatment effect stored `object` `Y` supplied, point estimate computed via est_effect without variance estimate. type character string specifying treatment effect estimate using est_effect. Options: - `\"Y\"`: Computes weighted mean outcome. - `\"ATE\"` (default): Computes Average Treatment Effect. - `\"ATT\"`: Computes Average Treatment Effect Treated. model already stores treatment effect (call lbc_net(..., Y = ..., estimand = ...)), stored type used instead argument. ... Additional arguments (ignored).","code":""},{"path":"/reference/summary.lbc_net.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary of an lbc_net Object — summary.lbc_net","text":"list containing: sample_info Sample sizes covariate counts. losses Training losses. local_balance Local standardized differences training. balance_table Pre- post-weighting global standardized differences (GSD). treatment_effect Estimated treatment effect , available,     standard error confidence interval. gsd GSD weighting.","code":""},{"path":"/reference/summary.lbc_net.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summary of an lbc_net Object — summary.lbc_net","text":"function extracts key model components using getLBC. fitted object contains stored treatment effect (e.g., call lbc_net(..., Y = ..., estimand = ..., compute_variance = TRUE)), summary.lbc_net reports estimate together standard error 95% confidence interval. treatment effect stored `Y` supplied, est_effect used compute point estimate (variance). neither available, summary focuses balance diagnostics. designed estimating causal effects settings continuous binary outcomes. survival outcomes, users apply appropriate survival analysis models, weighted Cox model time--event estimation methods.","code":""},{"path":[]},{"path":"/reference/summary.lbc_net.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary of an lbc_net Object — summary.lbc_net","text":"","code":"if (FALSE) { # \\dontrun{ model <- lbc_net(data = data, formula = Tr ~ X1 + X2 + X3 + X4) summary(model)  # Summary without treatment effect estimation summary(model, Y = my_outcome, type = \"ATE\")  # Summary including treatment effect  out <- summary(model) names(out) out$balance_table } # }"},{"path":"/reference/summary.lbc_net_surv.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary of an lbc_net_surv Object — summary.lbc_net_surv","title":"Summary of an lbc_net_surv Object — summary.lbc_net_surv","text":"Provides structured summary \"lbc_net_surv\" object, including training loss, balance assessments, estimated survival difference standard error confidence interval grid time points.","code":""},{"path":"/reference/summary.lbc_net_surv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary of an lbc_net_surv Object — summary.lbc_net_surv","text":"","code":"# S3 method for class 'lbc_net_surv' summary(object, ...)"},{"path":"/reference/summary.lbc_net_surv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary of an lbc_net_surv Object — summary.lbc_net_surv","text":"object object class \"lbc_net_surv\", generated lbc_net_surv(). ... Additional arguments (ignored).","code":""},{"path":"/reference/summary.lbc_net_surv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary of an lbc_net_surv Object — summary.lbc_net_surv","text":"list containing: sample_info Sample sizes covariate counts. loss Training loss. local_balance Local standardized differences (LSD) training. balance_table Pre- post-weighting global standardized         differences (GSD). survival Estimated survival curves \\(S_1(t)\\), \\(S_0(t)\\),         survival difference, standard errors, confidence intervals         evaluation grid. gsd GSD weighting.","code":""},{"path":"/reference/summary.lbc_net_surv.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summary of an lbc_net_surv Object — summary.lbc_net_surv","text":"function extracts key model components using getLBC fitted object. reports: Sample size covariate dimensions; Training loss local balance diagnostics (LSD); Global standardized differences (GSD) weighting; estimated survival difference \\(\\Delta(t) = S_1(t) - S_0(t)\\)         evaluation time grid, including standard errors         Wald 95% confidence intervals. method specifically designed survival outcomes fitted via lbc_net_surv. non-survival outcomes, use summary.lbc_net instead.","code":""},{"path":[]},{"path":"/reference/summary.lbc_net_surv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary of an lbc_net_surv Object — summary.lbc_net_surv","text":"","code":"if (FALSE) { # \\dontrun{   fit_surv <- lbc_net_surv(     data    = dat,     formula = Tr ~ X1 + X2,     time    = \"time\",     delta   = \"delta\"   )   out <- summary(fit_surv)   names(out)   head(out$survival$survival_df) } # }"},{"path":"/reference/summary.lsd.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary of an lsd Object — summary.lsd","title":"Summary of an lsd Object — summary.lsd","text":"Provides structured summary `lsd` object.","code":""},{"path":"/reference/summary.lsd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary of an lsd Object — summary.lsd","text":"","code":"# S3 method for class 'lsd' summary(object, ...)"},{"path":"/reference/summary.lsd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary of an lsd Object — summary.lsd","text":"object object class `\"lsd\"`, generated `lsd()`. ... Additional arguments passed specific method.","code":""},{"path":"/reference/summary.lsd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary of an lsd Object — summary.lsd","text":"structured summary `lbc_net` object, including: Average local balance cks covariate. Local balance summary: `lsd_max`, `lsd_mean` local standardized mean difference calculated training. Sample characteristics: `sample_size`, `num_covariates`, `treated_size`, `control_size`.","code":""},{"path":"/reference/summary.lsd.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summary of an lsd Object — summary.lsd","text":"function extracts key model components using getLBC.","code":""},{"path":[]},{"path":"/reference/summary.lsd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary of an lsd Object — summary.lsd","text":"","code":"if (FALSE) { # \\dontrun{ model <- lbc_net(data = data, formula = Tr ~ X1 + X2 + X3 + X4) lsd_result <- lsd(model) summary(lsd_result) } # }"}]
